{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 13307113,
          "sourceType": "datasetVersion",
          "datasetId": 8434934
        },
        {
          "sourceId": 13374934,
          "sourceType": "datasetVersion",
          "datasetId": 8485621
        },
        {
          "sourceId": 13446948,
          "sourceType": "datasetVersion",
          "datasetId": 8535494
        },
        {
          "sourceId": 13579804,
          "sourceType": "datasetVersion",
          "datasetId": 8627395
        },
        {
          "sourceId": 13582659,
          "sourceType": "datasetVersion",
          "datasetId": 8629281
        }
      ],
      "dockerImageVersionId": 31154,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "TCC-C√≥digo",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AugustoGuimaraesUFRJ/Algoritmo-Grafos/blob/main/TCC_C%C3%B3digo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "JHVmT66F21tK"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "augustoguimaraes_bertimbau_tcc_model_path = kagglehub.dataset_download('augustoguimaraes/bertimbau-tcc-model')\n",
        "augustoguimaraes_miniml_path = kagglehub.dataset_download('augustoguimaraes/miniml')\n",
        "augustoguimaraes_treinamento_e_teste_path = kagglehub.dataset_download('augustoguimaraes/treinamento-e-teste')\n",
        "augustoguimaraes_treino_mlm_path = kagglehub.dataset_download('augustoguimaraes/treino-mlm')\n",
        "augustoguimaraes_treinamentoad_path = kagglehub.dataset_download('augustoguimaraes/treinamentoad')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "6XXErw-i21tN"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import random\n",
        "import re\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import (\n",
        "    BertTokenizer, BertForMaskedLM,\n",
        "    AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import os\n",
        "import unicodedata\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import logging\n",
        "\n",
        "# Desativa qualquer barra de progresso do tqdm e logs do transformers\n",
        "tqdm.disable = True\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T19:39:16.401414Z",
          "iopub.execute_input": "2025-11-01T19:39:16.401957Z",
          "iopub.status.idle": "2025-11-01T19:39:16.407792Z",
          "shell.execute_reply.started": "2025-11-01T19:39:16.401935Z",
          "shell.execute_reply": "2025-11-01T19:39:16.407034Z"
        },
        "id": "AA42m31d21tO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/bertimbau-tcc-model/bert-base-portuguese-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"‚úÖ Modelo carregado no dispositivo: {device}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-02T04:33:29.531043Z",
          "iopub.execute_input": "2025-11-02T04:33:29.531594Z",
          "iopub.status.idle": "2025-11-02T04:33:29.984746Z",
          "shell.execute_reply.started": "2025-11-02T04:33:29.531571Z",
          "shell.execute_reply": "2025-11-02T04:33:29.983971Z"
        },
        "id": "sq8mx0Sj21tO",
        "outputId": "3cd69b93-4d6f-485f-f9ab-ecc16bcfc073"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Modelo carregado no dispositivo: cuda\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Caminhos dos arquivos\n",
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "test_path = \"/kaggle/input/treinamento-e-teste/test_df.csv\"\n",
        "\n",
        "# Carregar datasets\n",
        "train_final = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "#  Renomear 'class' ‚Üí 'labels'\n",
        "train_final = train_final.rename(columns={\"class\": \"labels\"})\n",
        "test_df = test_df.rename(columns={\"class\": \"labels\"})\n",
        "\n",
        "#  Remover nulos e garantir tipo string\n",
        "for name, df_ in {\"train\": train_final, \"test\": test_df}.items():\n",
        "    df_.dropna(subset=[\"text\", \"labels\"], inplace=True)\n",
        "    df_[\"text\"] = df_[\"text\"].astype(str)\n",
        "    df_.loc[df_[\"text\"].str.strip() == \"\", \"text\"] = np.nan\n",
        "    df_.dropna(subset=[\"text\"], inplace=True)\n",
        "    print(f\" {name}: {len(df_)} linhas\")\n",
        "\n",
        "#  Tokeniza√ß√£o\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_final)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# ============================================================\n",
        "# 9 Treinamento e avalia√ß√£o\n",
        "# ============================================================\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n",
        "\n",
        "# ============================================================\n",
        "# 9. An√°lise de Erros\n",
        "# ============================================================\n",
        "preds_output = trainer.predict(test_dataset)\n",
        "preds = np.argmax(preds_output.predictions, axis=1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "result_df[\"preds\"] = preds\n",
        "\n",
        "total = len(result_df)\n",
        "acertos = (result_df[\"labels\"] == result_df[\"preds\"]).sum()\n",
        "erros = total - acertos\n",
        "fp = ((result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)).sum()\n",
        "fn = ((result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)).sum()\n",
        "\n",
        "print(f\"\\n=== RESULTADOS DE ERRO ===\")\n",
        "print(f\"Total: {total}\")\n",
        "print(f\" Acertos: {acertos}\")\n",
        "print(f\" Erros: {erros}\")\n",
        "print(f\"  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): {fp}\")\n",
        "print(f\"  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): {fn}\")\n",
        "\n",
        "# Mostrar exemplos\n",
        "falsos_positivos = result_df[(result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)]\n",
        "falsos_negativos = result_df[(result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)]\n",
        "\n",
        "print(\"\\n===  FALSOS POSITIVOS ===\")\n",
        "for t in falsos_positivos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)\n",
        "\n",
        "print(\"\\n===  FALSOS NEGATIVOS ===\")\n",
        "for t in falsos_negativos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T17:08:53.405118Z",
          "iopub.execute_input": "2025-11-01T17:08:53.40593Z",
          "iopub.status.idle": "2025-11-01T17:10:50.090678Z",
          "shell.execute_reply.started": "2025-11-01T17:08:53.405896Z",
          "shell.execute_reply": "2025-11-01T17:10:50.089904Z"
        },
        "colab": {
          "referenced_widgets": [
            "fd191c0cdb714df5a526b0811bf8c121",
            "b457ed1022354451882d4cf0f910ca45"
          ]
        },
        "id": "N1u89Qsh21tP",
        "outputId": "964318d7-dc44-4c2c-f217-f838e0485093"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": " train: 5322 linhas\n test: 1331 linhas\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/5322 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd191c0cdb714df5a526b0811bf8c121"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b457ed1022354451882d4cf0f910ca45"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/2487770449.py:63: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.5415, 'grad_norm': 16.501218795776367, 'learning_rate': 1.705705705705706e-05, 'epoch': 0.15015015015015015}\n{'loss': 0.3196, 'grad_norm': 8.104938507080078, 'learning_rate': 1.4054054054054055e-05, 'epoch': 0.3003003003003003}\n{'loss': 0.2922, 'grad_norm': 8.398772239685059, 'learning_rate': 1.1051051051051051e-05, 'epoch': 0.45045045045045046}\n{'loss': 0.273, 'grad_norm': 2.8173561096191406, 'learning_rate': 8.048048048048048e-06, 'epoch': 0.6006006006006006}\n{'loss': 0.2734, 'grad_norm': 21.57377052307129, 'learning_rate': 5.045045045045045e-06, 'epoch': 0.7507507507507507}\n{'loss': 0.2606, 'grad_norm': 2.817598581314087, 'learning_rate': 2.0420420420420424e-06, 'epoch': 0.9009009009009009}\n{'eval_loss': 0.23450876772403717, 'eval_accuracy': 0.9120961682945155, 'eval_precision': 0.9159159159159159, 'eval_recall': 0.9090909090909091, 'eval_f1': 0.912490650710546, 'eval_runtime': 6.9917, 'eval_samples_per_second': 190.369, 'eval_steps_per_second': 12.014, 'epoch': 1.0}\n{'train_runtime': 97.7195, 'train_samples_per_second': 54.462, 'train_steps_per_second': 3.408, 'train_loss': 0.3201548602129962, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.23450876772403717, 'eval_accuracy': 0.9120961682945155, 'eval_precision': 0.9159159159159159, 'eval_recall': 0.9090909090909091, 'eval_f1': 0.912490650710546, 'eval_runtime': 7.3556, 'eval_samples_per_second': 180.951, 'eval_steps_per_second': 11.42, 'epoch': 1.0}\n{'eval_loss': 0.23450876772403717, 'eval_accuracy': 0.9120961682945155, 'eval_precision': 0.9159159159159159, 'eval_recall': 0.9090909090909091, 'eval_f1': 0.912490650710546, 'eval_runtime': 7.3556, 'eval_samples_per_second': 180.951, 'eval_steps_per_second': 11.42, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n=== RESULTADOS DE ERRO ===\nTotal: 1331\n Acertos: 1214\n Erros: 117\n  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): 56\n  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): 61\n\n===  FALSOS POSITIVOS ===\n‚Ä¢ Cada dia se queimando mais\n‚Ä¢ √â a treva.\n‚Ä¢ SENSACIONAL √â BEM P√îR AI MESMOOO, ELE EST√Å PREOCUPADO PORQU√ä SERA, QUEM √ë DEVE √ë TEME, SIMPLES ASSIM!!!\n‚Ä¢ O Brasil lutando para sair da Grota e alguns preocupado com a tal de Greta. Vamos ficar at√© quando nessa?\n‚Ä¢ Dupla imbat√≠vel nas argumenta√ß√µes inteligentes contra esse governo desgovernado que estamos pagando....aff\n‚Ä¢ E n√≥s que podemos ter perdido uma Greta Thunberg cruelmente assasinada por witizelassassino witizelgenocida. √Åghata nossa Menina Maravilha tinha apenas 8 anos seu discurso era apenas a boneca M√¥nica, mas quem poder√° afirmar ao contr√°rio que aos 16 anos trocaria M√¥nica pela bandeira de um mundo mais justo e sustent√°vel.\n‚Ä¢ Nem era pra ter sido preso! LulaInocente\n‚Ä¢ Uma menina chega as capas aos 16 anos e n√£o s√£o em p√°ginas policiais,muito contr√°rio dos pol√≠ticos desse pa√≠s que s√≥ faz vergonha ao inv√©s de cumprir seus mandados e os objetivos e promessas de melhoras. N√≥s fizemos a nossa parte,tiramos um governo corrupto do trono,agora quem t√° l√° abre a boca e fala merda. S√≥ lembrando que n√≥s TIRAMOS e COLOCAMOS vcs,N√≥s o POVO.\n‚Ä¢ Bene disse tudo. Esse ign√≥bil faltou aulas de Hist√≥ria.\n‚Ä¢ Deixando de seguir, pq so perde tempo implicando com os bolsonaros...3...2..1...fui!\n‚Ä¢ Meu amigo.. pol√≠tica n√£o √© pra fracos n√£o... Meu amigo √© muita treta. Tamb√©m, enquanto os sal√°rios forem altos ter√° at√© mortes, como tem. Era pra ser sal√°rio de professor isso a√≠\n‚Ä¢ So negros morrem no Brasil? Bandido nao escolhe cor!\n‚Ä¢ acho que esse, menininho odeia o pai. s√≥ faz M.\n‚Ä¢ E tem gado do bozo q ainda aplaude!\n‚Ä¢ Deveria ter pena da Venezuela !!!!\n‚Ä¢ E direitos, fora bolsonaro\n‚Ä¢ haddad e freixo futuro do brasil\n‚Ä¢ Ela deveria dizer. T√î PREOCUPADA COM A LAVA JATO DO BRASIL NA MINHA COLA\n‚Ä¢ Abra um col√©gio militar em S√£o Gabriel da Cachoeira, na cabe√ßa do Cachorro!! Precisa muito!!!\n‚Ä¢ Que horror!\n‚Ä¢ Doida pra ter esse gato como meu presente.\n‚Ä¢ Para de progudicar o governo parem de botar leinha na fogueira, so demora afala mas quando falam sai fais por todo lado !!!\n‚Ä¢ S√≥ pensando no chilique dos sulistas facistas que l√° s√£o maioria.\n‚Ä¢ O q fortalece a esquerda s√£o os traidores q se elegeram as custas do presidente e depois de eleitos o apunhalam pelas costas. Isso sim!!!\n‚Ä¢ Nesse meio ronda energias ruins e pessoas m√°s, SO orando pedindo for√ßas dos c√©us, SO DEUS pra derrubar essas trevas.\n‚Ä¢ Hahahaha eh uma piada. Que chicote, parou em 1888? Demagogia pura, como combateremos racismo com racismo, preconceito com preconceito?\n‚Ä¢ Boa ministro ningu√©m est√° acima da lei, acabou para os corruptos e canalhas!! Pra cima deles!!\n‚Ä¢ Ricardo Coutinho voc√™ √© o cara minha expira√ß√£o\n‚Ä¢ Sou negr√£o e essa mulher n√£o me representa ...\n‚Ä¢ Tem dinheiro... responde em liberdade lament√°vel\n\n===  FALSOS NEGATIVOS ===\n‚Ä¢ joicetraidora\n‚Ä¢ Tem que prender por incita√ß√£o a viol√™ncia.\n‚Ä¢ Faz me rir!!!\n‚Ä¢ Horr√≠vel! Silvio precisa ser parado urgente!!!\n‚Ä¢ Incompetente ela sempre foi!\n‚Ä¢ Terrorismo, al√©m do preconceito contra RORAIMA\n‚Ä¢ Ser√°,,Kkkk,,,,vcs mentem tanto mais tanto,,,,,parab√©ns Bolsonaro senta lenha\n‚Ä¢ Circo\n‚Ä¢ Ela pode militar uma causa importante, mas essa voz chorosa for√ßada n√£o agrega, muito pelo contr√°rio. Parece apenas uma menina hist√©rica e muito chata. Podemos creditar isso a uma imaturidade, mas ela poderia ter sido melhor aconselhada. Perdi a simpatia por ela.\n‚Ä¢ Isso √© um arrast√£o?\n‚Ä¢ Interven√ß√£o militar no STF, j√°\n‚Ä¢ Parece que se a mulher √© de direita ela n√£o merece ser respeitada segundo jornais de Esquerda, pois n√£o hesitaram nem um minuto em massacrar a mulher\n‚Ä¢ Sra Leilane repita comigo por favor por v√°rias vezes !! ME FUDI !!!!! Kkkkk\n‚Ä¢ O que √© dela t√° guardado\n‚Ä¢ As pessoas normais e que ainda t√™m capacidade de ver e entender o que est√° acontecendo\n‚Ä¢ √â porque a Pepa tem o mesmo esp√≠rito ruim do Mula! Deus n√£o ajuda a ficar no alto,a ficar bem,t√° sempre se l!Minha m√£e dizia Quem muito quer nada tem! √â o caso dela e do Mula! Beij√£o pra vc Carla! Estamos com vc e os bons do Congresso!\n‚Ä¢ .zambelli eu gosto do seu trabalho e adimiro voc√™, o melhor rem√©dio ignore a Joicehasselmann, ela n√£o merece perda de tempo com ela, j√° est√° acabada!!!\n‚Ä¢ F A L I D A ! ! !\n‚Ä¢ Joice mente t√£o bem que at√© mesmo ela acredita na pr√≥pria mentira. Triste fim. Triste\n‚Ä¢ Terrivelmente evang√©lico\n‚Ä¢ Deviamos invadir o insta dessa carta capital e falar oq eles merecem ler...senti a ang√∫stia nas palavras da ministra Damares...estou contigo\n‚Ä¢ N√ÉO!! Pera √â s√©rio isso?! Mais um CUPIM? Vamos l√° galera!! Vamos tocar em assuntos irrelevantes para ENFRAQUECER a na√ß√£o. Se n√£o temos nada contra ele, vamos enfraquecer o povo. Fingindo estar preocupada com o bem da na√ß√£o, tu chapas cana e assobia ao mesmo tempo. Finge estar preocupada com a na√ß√£o jogando pedras no presidente para enfraquecer nossa confian√ßa nele, mas na VERDADE tu estas trabalhando com e para os inimigos DEUS SABE PORQUE. Ent√£o, vamos relevar um detalhe importante TODOS SABEM QUEM √â ESSA PIRRALHA, PRA QM ELA TRABALHA, O Q ELES REALMENTE QUEREM. Uma interpreta√ß√£o simples de texto mostra NOSSO PRESIDENTE disse q ela √© um objeto q lucra muito, abrindo caminhos para o q querem devorar nosso pa√≠s. PIRRALHA Ser pequeno que usa sua aparente inoc√™ncia para abrir caminho para EXPLORADORES. Pode n√£o ter classe na palavras do PRESIDENTE, mas elas tem VERDADE E SINCERIDADE.\n‚Ä¢ Pessoal , vamos nos unir sempre. Kim e MBL s√£o nossos aliados. A esquerda deste pa√≠s se junta e n√£o t√™m car√°ter. Ponto. A direita precisa ser firme. Um ou outro ponto poder√° ser divergido. Normal. Conversem. DIREITA sempre. Unidos √© que vencemos eles. Kim √© um pol√≠tico honesto. Ele s√≥ precisa ter maldade. E sair do DEM. Claro\n‚Ä¢ duas notas de 3\n‚Ä¢ N√£o entendo. Por que n√£o o prenderam imediatamente por incita√ß√£o √† viol√™ncia? Quanto mais tempo ele passar livre, pior para a Na√ß√£o!\n‚Ä¢ O nome disso n√£o senilidade, chamase PEDOFILIA!!!\n‚Ä¢ Incitando o √≥dio a guerra ,vandalismo\n‚Ä¢ D√©bil. ..\n‚Ä¢ O √≥dio da esquerda √© maior que o seu amor pelo Brasil, vale at√© quebrar o pa√≠s se isso prejudicar o Bolsonaro, n√£o importa se o brasileiro se FODE junto, importante √© que atrapalharam o Bolsonaro!!\n‚Ä¢ Pnc\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "train_df = train_df[train_df['text'].apply(lambda x: isinstance(x, str) and x.strip() != '')]\n",
        "print(\"üìä Linhas totais:\", len(train_df))\n",
        "print(train_df.info())\n",
        "print(\"\\nAmostra de tipos incorretos:\")\n",
        "print(train_df[~train_df['text'].apply(lambda x: isinstance(x, str))].head())"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:12:35.206295Z",
          "iopub.execute_input": "2025-11-01T18:12:35.206638Z",
          "iopub.status.idle": "2025-11-01T18:12:35.244097Z",
          "shell.execute_reply.started": "2025-11-01T18:12:35.206618Z",
          "shell.execute_reply": "2025-11-01T18:12:35.24336Z"
        },
        "id": "7VkvIykj21tQ",
        "outputId": "8550c4e0-d79d-4516-e03f-d0d346fd2785"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "üìä Linhas totais: 5322\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5322 entries, 0 to 5321\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    5322 non-null   object\n 1   class   5322 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 83.3+ KB\nNone\n\nAmostra de tipos incorretos:\nEmpty DataFrame\nColumns: [text, class]\nIndex: []\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/bertimbau-tcc-model/bert-base-portuguese-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"‚úÖ Modelo carregado no dispositivo: {device}\")\n",
        "\n",
        "def mlm_augment(text, idx=None, prob=0.15, n_aug=2):\n",
        "    \"\"\"\n",
        "    Gera frases aumentadas via Masked Language Modeling (BERTimbau)\n",
        "    e associa cada uma ao √≠ndice original do texto.\n",
        "\n",
        "    Args:\n",
        "        text (str): Texto original.\n",
        "        idx (int, optional): √çndice da frase original no dataset.\n",
        "        prob (float): Probabilidade de mascarar um token.\n",
        "        n_aug (int): Quantas vers√µes aumentadas gerar.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: Lista com {\"orig_idx\", \"text_original\", \"text_augmentada\"}\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    augmented_samples = []\n",
        "\n",
        "    for _ in range(n_aug):\n",
        "        masked_tokens = tokens.copy()\n",
        "        for i in range(len(masked_tokens)):\n",
        "            if random.random() < prob and masked_tokens[i].isalpha():\n",
        "                masked_tokens[i] = tokenizer.mask_token\n",
        "\n",
        "        masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "        inputs = tokenizer(masked_text, return_tensors='pt').to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = outputs.logits\n",
        "\n",
        "        predicted_indices = torch.argmax(predictions, dim=-1)\n",
        "        if predicted_indices.dim() == 0:\n",
        "            predicted_indices = predicted_indices.unsqueeze(0)\n",
        "\n",
        "        predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indices[0].tolist())\n",
        "\n",
        "        result_tokens = [\n",
        "            predicted_tokens[i] if masked_tokens[i] == tokenizer.mask_token else masked_tokens[i]\n",
        "            for i in range(len(masked_tokens))\n",
        "        ]\n",
        "\n",
        "        new_text = tokenizer.convert_tokens_to_string(result_tokens)\n",
        "        augmented_samples.append({\n",
        "            \"orig_idx\": idx,\n",
        "            \"text_original\": text,\n",
        "            \"text_augmentada\": new_text\n",
        "        })\n",
        "\n",
        "    return augmented_samples\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Carregar dataset\n",
        "# ============================================================\n",
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "# Itera sobre cada linha do treino\n",
        "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
        "    # Gera novas vers√µes da frase\n",
        "    new_samples = mlm_augment(\n",
        "        text=row[\"text\"],\n",
        "        idx=idx,           # √≠ndice original da linha no treino\n",
        "        prob=0.15,         # 15% das palavras mascaradas\n",
        "        n_aug=2            # duas vers√µes aumentadas por frase\n",
        "    )\n",
        "\n",
        "    # Adiciona resultados ao dataset final\n",
        "    for sample in new_samples:\n",
        "        new_text = sample[\"text_augmentada\"]\n",
        "\n",
        "        augmented_rows.append({\n",
        "            \"orig_idx\": sample[\"orig_idx\"],\n",
        "            \"text_original\": sample[\"text_original\"],\n",
        "            \"text_augmentada\": new_text,\n",
        "            \"class\": row[\"class\"]\n",
        "        })\n",
        "\n",
        "# Cria DataFrame com os textos aumentados\n",
        "df_aug = pd.DataFrame(augmented_rows)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:31:32.382546Z",
          "iopub.execute_input": "2025-11-01T18:31:32.383282Z",
          "iopub.status.idle": "2025-11-01T18:33:06.541392Z",
          "shell.execute_reply.started": "2025-11-01T18:31:32.383258Z",
          "shell.execute_reply": "2025-11-01T18:33:06.540692Z"
        },
        "id": "RcoV4sVL21tQ",
        "outputId": "f98a4783-0813-4cbd-b69e-b85a66171636"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Modelo carregado no dispositivo: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5322/5322 [01:33<00:00, 56.81it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug= df_aug[[\"text_augmentada\", \"class\"]].rename(columns={\"text_augmentada\": \"text\"})\n",
        "\n",
        "print(df_aug.shape)\n",
        "df_aug.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:33:13.824888Z",
          "iopub.execute_input": "2025-11-01T18:33:13.825189Z",
          "iopub.status.idle": "2025-11-01T18:33:13.835422Z",
          "shell.execute_reply.started": "2025-11-01T18:33:13.825151Z",
          "shell.execute_reply": "2025-11-01T18:33:13.834814Z"
        },
        "id": "VGSVoB7621tR",
        "outputId": "f7672140-4701-4944-bf2c-8e6b50a314fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(10644, 2)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                       text  class\n0   Parab√©ns meu presidente      0\n1          Parab√©ns meu meu      0\n2          Valeuu analise .      0\n3          Valeu seu seue .      0\n4  PT roubando o o povo ! !      1",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Parab√©ns meu presidente</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Parab√©ns meu meu</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Valeuu analise .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Valeu seu seue .</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>PT roubando o o povo ! !</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(train_path)\n",
        "train_df.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:33:23.796668Z",
          "iopub.execute_input": "2025-11-01T18:33:23.797381Z",
          "iopub.status.idle": "2025-11-01T18:33:23.814773Z",
          "shell.execute_reply.started": "2025-11-01T18:33:23.797358Z",
          "shell.execute_reply": "2025-11-01T18:33:23.814207Z"
        },
        "id": "h3zlP-eb21tS",
        "outputId": "3e335ab7-2218-45ab-872b-50bc74443b2d"
      },
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                           text  class\n0       Parab√©ns meu presidente      0\n1            Valeu seu analise.      0\n2  PT roubando o pa√≠s inteiro!!      1\n3                   Lula livre.      0\n4    Ele esqueceu de amadurecer      0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Parab√©ns meu presidente</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valeu seu analise.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PT roubando o pa√≠s inteiro!!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lula livre.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ele esqueceu de amadurecer</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_final = pd.concat([train_df, df_aug], ignore_index=True)\n",
        "train_final.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:23:51.851336Z",
          "iopub.execute_input": "2025-11-01T18:23:51.85201Z",
          "iopub.status.idle": "2025-11-01T18:23:51.864291Z",
          "shell.execute_reply.started": "2025-11-01T18:23:51.851986Z",
          "shell.execute_reply": "2025-11-01T18:23:51.863579Z"
        },
        "id": "tQpFL2Wq21tS",
        "outputId": "9f291711-5559-461a-ebc3-41bb99fc97fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n",
          "output_type": "stream"
        },
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                           text  labels  class\n0       Parab√©ns meu presidente     0.0    NaN\n1            Valeu seu analise.     0.0    NaN\n2  PT roubando o pa√≠s inteiro!!     1.0    NaN\n3                   Lula livre.     0.0    NaN\n4    Ele esqueceu de amadurecer     0.0    NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>labels</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Parab√©ns meu presidente</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Valeu seu analise.</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>PT roubando o pa√≠s inteiro!!</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Lula livre.</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ele esqueceu de amadurecer</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "test_path = \"/kaggle/input/treinamento-e-teste/test_df.csv\"\n",
        "\n",
        "# Carregar datasets\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_final = pd.concat([train_df, df_aug], ignore_index=True)\n",
        "\n",
        "#  Renomear 'class' ‚Üí 'labels'\n",
        "train_final = train_final.rename(columns={\"class\": \"labels\"})\n",
        "test_df = test_df.rename(columns={\"class\": \"labels\"})\n",
        "\n",
        "\n",
        "train_final = train_final[~train_final[\"text\"].str.contains(r\"\\[UNK\\]\", regex=True, na=False)]\n",
        "train_final = train_final.drop_duplicates(subset=[\"text\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "#  Remover nulos e garantir tipo string\n",
        "for name, df_ in {\"train\": train_final, \"test\": test_df}.items():\n",
        "    df_.dropna(subset=[\"text\", \"labels\"], inplace=True)\n",
        "    df_[\"text\"] = df_[\"text\"].astype(str)\n",
        "    df_.loc[df_[\"text\"].str.strip() == \"\", \"text\"] = np.nan\n",
        "    df_.dropna(subset=[\"text\"], inplace=True)\n",
        "    print(f\" {name}: {len(df_)} linhas\")\n",
        "\n",
        "#  Tokeniza√ß√£o\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_final)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# ============================================================\n",
        "# 9 Treinamento e avalia√ß√£o\n",
        "# ============================================================\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n",
        "\n",
        "# ============================================================\n",
        "# 9. An√°lise de Erros\n",
        "# ============================================================\n",
        "preds_output = trainer.predict(test_dataset)\n",
        "preds = np.argmax(preds_output.predictions, axis=1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "result_df[\"preds\"] = preds\n",
        "\n",
        "total = len(result_df)\n",
        "acertos = (result_df[\"labels\"] == result_df[\"preds\"]).sum()\n",
        "erros = total - acertos\n",
        "fp = ((result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)).sum()\n",
        "fn = ((result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)).sum()\n",
        "\n",
        "print(f\"\\n=== RESULTADOS DE ERRO ===\")\n",
        "print(f\"Total: {total}\")\n",
        "print(f\" Acertos: {acertos}\")\n",
        "print(f\" Erros: {erros}\")\n",
        "print(f\"  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): {fp}\")\n",
        "print(f\"  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): {fn}\")\n",
        "\n",
        "# Mostrar exemplos\n",
        "falsos_positivos = result_df[(result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)]\n",
        "falsos_negativos = result_df[(result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)]\n",
        "\n",
        "print(\"\\n===  FALSOS POSITIVOS ===\")\n",
        "for t in falsos_positivos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)\n",
        "\n",
        "print(\"\\n===  FALSOS NEGATIVOS ===\")\n",
        "for t in falsos_negativos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:33:37.061578Z",
          "iopub.execute_input": "2025-11-01T18:33:37.062136Z",
          "iopub.status.idle": "2025-11-01T18:38:02.886703Z",
          "shell.execute_reply.started": "2025-11-01T18:33:37.062115Z",
          "shell.execute_reply": "2025-11-01T18:38:02.886049Z"
        },
        "colab": {
          "referenced_widgets": [
            "54e91237a32d493ab8ca1e0cbc3086cc",
            "23089d3900d5468dba42ffcb42bdc288"
          ]
        },
        "id": "JtfsqZag21tT",
        "outputId": "2f85cbc6-a47e-4d1a-e5a5-07418b7010a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": " train: 13232 linhas\n test: 1331 linhas\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/13232 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "54e91237a32d493ab8ca1e0cbc3086cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23089d3900d5468dba42ffcb42bdc288"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/719385155.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.5433, 'grad_norm': 10.164219856262207, 'learning_rate': 1.8814993954050786e-05, 'epoch': 0.060459492140266025}\n{'loss': 0.3297, 'grad_norm': 10.76231575012207, 'learning_rate': 1.760580411124547e-05, 'epoch': 0.12091898428053205}\n{'loss': 0.2985, 'grad_norm': 8.488628387451172, 'learning_rate': 1.6396614268440147e-05, 'epoch': 0.18137847642079807}\n{'loss': 0.2696, 'grad_norm': 28.817798614501953, 'learning_rate': 1.5187424425634827e-05, 'epoch': 0.2418379685610641}\n{'loss': 0.301, 'grad_norm': 6.734292984008789, 'learning_rate': 1.3978234582829506e-05, 'epoch': 0.3022974607013301}\n{'loss': 0.2726, 'grad_norm': 7.549954414367676, 'learning_rate': 1.2769044740024186e-05, 'epoch': 0.36275695284159615}\n{'loss': 0.2785, 'grad_norm': 14.627341270446777, 'learning_rate': 1.1559854897218865e-05, 'epoch': 0.42321644498186217}\n{'loss': 0.2576, 'grad_norm': 8.157594680786133, 'learning_rate': 1.0350665054413544e-05, 'epoch': 0.4836759371221282}\n{'loss': 0.2148, 'grad_norm': 4.0247907638549805, 'learning_rate': 9.141475211608223e-06, 'epoch': 0.5441354292623942}\n{'loss': 0.2026, 'grad_norm': 9.729497909545898, 'learning_rate': 7.932285368802901e-06, 'epoch': 0.6045949214026602}\n{'loss': 0.2151, 'grad_norm': 11.114466667175293, 'learning_rate': 6.723095525997582e-06, 'epoch': 0.6650544135429263}\n{'loss': 0.2281, 'grad_norm': 7.759106159210205, 'learning_rate': 5.513905683192262e-06, 'epoch': 0.7255139056831923}\n{'loss': 0.206, 'grad_norm': 14.798752784729004, 'learning_rate': 4.304715840386941e-06, 'epoch': 0.7859733978234583}\n{'loss': 0.1818, 'grad_norm': 11.323305130004883, 'learning_rate': 3.0955259975816203e-06, 'epoch': 0.8464328899637243}\n{'loss': 0.1875, 'grad_norm': 1.9886808395385742, 'learning_rate': 1.8863361547763e-06, 'epoch': 0.9068923821039904}\n{'loss': 0.2072, 'grad_norm': 11.51394271850586, 'learning_rate': 6.771463119709795e-07, 'epoch': 0.9673518742442564}\n{'eval_loss': 0.25742781162261963, 'eval_accuracy': 0.9143501126972201, 'eval_precision': 0.908957415565345, 'eval_recall': 0.9225037257824144, 'eval_f1': 0.9156804733727811, 'eval_runtime': 7.2353, 'eval_samples_per_second': 183.958, 'eval_steps_per_second': 11.61, 'epoch': 1.0}\n{'train_runtime': 245.485, 'train_samples_per_second': 53.901, 'train_steps_per_second': 3.369, 'train_loss': 0.2587460923800301, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.25742781162261963, 'eval_accuracy': 0.9143501126972201, 'eval_precision': 0.908957415565345, 'eval_recall': 0.9225037257824144, 'eval_f1': 0.9156804733727811, 'eval_runtime': 7.2263, 'eval_samples_per_second': 184.188, 'eval_steps_per_second': 11.624, 'epoch': 1.0}\n{'eval_loss': 0.25742781162261963, 'eval_accuracy': 0.9143501126972201, 'eval_precision': 0.908957415565345, 'eval_recall': 0.9225037257824144, 'eval_f1': 0.9156804733727811, 'eval_runtime': 7.2263, 'eval_samples_per_second': 184.188, 'eval_steps_per_second': 11.624, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n=== RESULTADOS DE ERRO ===\nTotal: 1331\n Acertos: 1217\n Erros: 114\n  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): 62\n  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): 52\n\n===  FALSOS POSITIVOS ===\n‚Ä¢ Cada dia se queimando mais\n‚Ä¢ √â a treva.\n‚Ä¢ Isto mesmo. Esses filhos do Sr. Presidente deveriam ficar mais falados. V√£o colocar tudo a perder. Uma l√°stima.\n‚Ä¢ Jesus, √© cada uma desse cidad√£o. √â de assustar.\n‚Ä¢ SENSACIONAL √â BEM P√îR AI MESMOOO, ELE EST√Å PREOCUPADO PORQU√ä SERA, QUEM √ë DEVE √ë TEME, SIMPLES ASSIM!!!\n‚Ä¢ A√™ num aguento!\n‚Ä¢ Aro\n‚Ä¢ Dupla imbat√≠vel nas argumenta√ß√µes inteligentes contra esse governo desgovernado que estamos pagando....aff\n‚Ä¢ E n√≥s que podemos ter perdido uma Greta Thunberg cruelmente assasinada por witizelassassino witizelgenocida. √Åghata nossa Menina Maravilha tinha apenas 8 anos seu discurso era apenas a boneca M√¥nica, mas quem poder√° afirmar ao contr√°rio que aos 16 anos trocaria M√¥nica pela bandeira de um mundo mais justo e sustent√°vel.\n‚Ä¢ Essa menina sozinha ta fazendo mais que uma na√ß√£o.\n‚Ä¢ Nem era pra ter sido preso! LulaInocente\n‚Ä¢ Ent√£o os jornalistas, a folha a Globo v√£o ser todos punidos??\n‚Ä¢ Uma menina chega as capas aos 16 anos e n√£o s√£o em p√°ginas policiais,muito contr√°rio dos pol√≠ticos desse pa√≠s que s√≥ faz vergonha ao inv√©s de cumprir seus mandados e os objetivos e promessas de melhoras. N√≥s fizemos a nossa parte,tiramos um governo corrupto do trono,agora quem t√° l√° abre a boca e fala merda. S√≥ lembrando que n√≥s TIRAMOS e COLOCAMOS vcs,N√≥s o POVO.\n‚Ä¢ Bene disse tudo. Esse ign√≥bil faltou aulas de Hist√≥ria.\n‚Ä¢ Deixando de seguir, pq so perde tempo implicando com os bolsonaros...3...2..1...fui!\n‚Ä¢ Meu amigo.. pol√≠tica n√£o √© pra fracos n√£o... Meu amigo √© muita treta. Tamb√©m, enquanto os sal√°rios forem altos ter√° at√© mortes, como tem. Era pra ser sal√°rio de professor isso a√≠\n‚Ä¢ So negros morrem no Brasil? Bandido nao escolhe cor!\n‚Ä¢ acho que esse, menininho odeia o pai. s√≥ faz M.\n‚Ä¢ Meu DeusO cara √© pastor! Fim dos tempos!\n‚Ä¢ E tem gado do bozo q ainda aplaude!\n‚Ä¢ Deveria ter pena da Venezuela !!!!\n‚Ä¢ E direitos, fora bolsonaro\n‚Ä¢ haddad e freixo futuro do brasil\n‚Ä¢ Ela deveria dizer. T√î PREOCUPADA COM A LAVA JATO DO BRASIL NA MINHA COLA\n‚Ä¢ Abra um col√©gio militar em S√£o Gabriel da Cachoeira, na cabe√ßa do Cachorro!! Precisa muito!!!\n‚Ä¢ Que horror!\n‚Ä¢ Para de progudicar o governo parem de botar leinha na fogueira, so demora afala mas quando falam sai fais por todo lado !!!\n‚Ä¢ Patroc√≠nio da esquerda internacional , n√£o tem fim a verba.\n‚Ä¢ O q fortalece a esquerda s√£o os traidores q se elegeram as custas do presidente e depois de eleitos o apunhalam pelas costas. Isso sim!!!\n‚Ä¢ Eita ferro,kkkkk\n\n===  FALSOS NEGATIVOS ===\n‚Ä¢ Tem que prender por incita√ß√£o a viol√™ncia.\n‚Ä¢ Faz me rir!!!\n‚Ä¢ Cuidado ao defender uma militante de esquerda. Ela se apegou a uma causa que nao tem solu√ßao. H√° muito por tras da far√ßa que ela se exp√µe.\n‚Ä¢ Terrorismo, al√©m do preconceito contra RORAIMA\n‚Ä¢ Ela pode militar uma causa importante, mas essa voz chorosa for√ßada n√£o agrega, muito pelo contr√°rio. Parece apenas uma menina hist√©rica e muito chata. Podemos creditar isso a uma imaturidade, mas ela poderia ter sido melhor aconselhada. Perdi a simpatia por ela.\n‚Ä¢ Isso √© um arrast√£o?\n‚Ä¢ Interven√ß√£o militar no STF, j√°\n‚Ä¢ Parece que se a mulher √© de direita ela n√£o merece ser respeitada segundo jornais de Esquerda, pois n√£o hesitaram nem um minuto em massacrar a mulher\n‚Ä¢ Sra Leilane repita comigo por favor por v√°rias vezes !! ME FUDI !!!!! Kkkkk\n‚Ä¢ Fodase.\n‚Ä¢ O que √© dela t√° guardado\n‚Ä¢ As pessoas normais e que ainda t√™m capacidade de ver e entender o que est√° acontecendo\n‚Ä¢ .zambelli eu gosto do seu trabalho e adimiro voc√™, o melhor rem√©dio ignore a Joicehasselmann, ela n√£o merece perda de tempo com ela, j√° est√° acabada!!!\n‚Ä¢ Esse...tem q sair do arm√°rio a√≠ n√£o sai fica assim\n‚Ä¢ Joice mente t√£o bem que at√© mesmo ela acredita na pr√≥pria mentira. Triste fim. Triste\n‚Ä¢ Deviamos invadir o insta dessa carta capital e falar oq eles merecem ler...senti a ang√∫stia nas palavras da ministra Damares...estou contigo\n‚Ä¢ Pessoal , vamos nos unir sempre. Kim e MBL s√£o nossos aliados. A esquerda deste pa√≠s se junta e n√£o t√™m car√°ter. Ponto. A direita precisa ser firme. Um ou outro ponto poder√° ser divergido. Normal. Conversem. DIREITA sempre. Unidos √© que vencemos eles. Kim √© um pol√≠tico honesto. Ele s√≥ precisa ter maldade. E sair do DEM. Claro\n‚Ä¢ duas notas de 3\n‚Ä¢ Vamos trabalhar? Ficar de picuinha n√£o vai ajudar o Brasil, esquece essa cobra e siga em frente.\n‚Ä¢ N√£o entendo. Por que n√£o o prenderam imediatamente por incita√ß√£o √† viol√™ncia? Quanto mais tempo ele passar livre, pior para a Na√ß√£o!\n‚Ä¢ Incitando o √≥dio a guerra ,vandalismo\n‚Ä¢ Voc√™s ainda n√£o entenderam a extrema esquerda revolucion√°ria voc√™ falando ou n√£o, fazendo ou n√£o, produzindo ou n√£o, atacando ou n√£o, se defendendo ou n√£o, eles querem o poder acima de tudo, onde o fim nustifica os meios. V√£o atacar violentamente e sistematicamente tudo aquilo que est√° fora dos interesses do partido. Isso √© um fato hist√≥rico. S√≥ no Brasil que enxergam a esquerda como um partido, quando a hist√≥ria nos prova o contr√°rio. N√£o √© uma quest√£o de dar muni√ß√£o para o oponente, e sim, de sobrevivencia em meio a uma m√°fia pol√≠tica criminosa que tomou conta o estamento burocr√°tico brasileiro, que se preciso for, mandam matar. Algu√©m ainda tem d√∫vidas?\n‚Ä¢ O √≥dio da esquerda √© maior que o seu amor pelo Brasil, vale at√© quebrar o pa√≠s se isso prejudicar o Bolsonaro, n√£o importa se o brasileiro se FODE junto, importante √© que atrapalharam o Bolsonaro!!\n‚Ä¢ Marquinho que parece gostar do verbo espancar, mmm?\n‚Ä¢ Cortei in√∫meras p√°ginas que n√£o √© oficial, tem comunista que entra nesses grupos que fazem campanha at√© para n√£o comer carne, √© bom a√≠ sobra e os produtores exportam mais ,E a greve segunda feira?.\n‚Ä¢ Isto sempre ficou muito claro, Bolsolixo √© contra os trabalhadores e o povo de bem num modo geral, ele ap√≥ia os milicianos, pronto a fazer qualquer desgra√ßa contra o povo.\n‚Ä¢ Na terra em que essa mulher africana √© bonita as trans s√£o mulheres. Surrealismo cl√°ssico.\n‚Ä¢ Eu tenho ran√ßo desse estocador de coc√¥, mas entendi o que ele quis dizer em rela√ß√£o √† Roraima. A popula√ß√£o desse estado teve muitos problemas com os imigrantes venezuelanos. Agora ele errou ao dizer, que um governo de esquerda na Argentina faria isso, est√° mais f√°cil a gente emigrar para l√° se isso acontecer.\n‚Ä¢ Deputada para com isso admiro seu trabalho mas essa menina tem q parar com isso muita pessoas dando moral a essa garota q se faz de Santa acho q vc esta ao lado dela ... Sou f√£ da senhora mas n√£o juga o presidente n√£o\n‚Ä¢ Ou derruba esse congresso e STF ou o Brasil ser√° derrubado.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"/kaggle/input/bertimbau-tcc-model/bert-base-portuguese-cased\"\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "model = BertForMaskedLM.from_pretrained(model_name)\n",
        "model.eval()\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "print(f\"‚úÖ Modelo carregado no dispositivo: {device}\")\n",
        "\n",
        "def mlm_augment(text, idx=None, prob=0.20, n_aug=5):\n",
        "    \"\"\"\n",
        "    Gera frases aumentadas via Masked Language Modeling (BERTimbau)\n",
        "    e associa cada uma ao √≠ndice original do texto.\n",
        "\n",
        "    Args:\n",
        "        text (str): Texto original.\n",
        "        idx (int, optional): √çndice da frase original no dataset.\n",
        "        prob (float): Probabilidade de mascarar um token.\n",
        "        n_aug (int): Quantas vers√µes aumentadas gerar.\n",
        "\n",
        "    Returns:\n",
        "        list[dict]: Lista com {\"orig_idx\", \"text_original\", \"text_augmentada\"}\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or text.strip() == \"\":\n",
        "        return []\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    augmented_samples = []\n",
        "\n",
        "    for _ in range(n_aug):\n",
        "        masked_tokens = tokens.copy()\n",
        "        for i in range(len(masked_tokens)):\n",
        "            if random.random() < prob and masked_tokens[i].isalpha():\n",
        "                masked_tokens[i] = tokenizer.mask_token\n",
        "\n",
        "        masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "        inputs = tokenizer(masked_text, return_tensors='pt').to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            predictions = outputs.logits\n",
        "\n",
        "        predicted_indices = torch.argmax(predictions, dim=-1)\n",
        "        if predicted_indices.dim() == 0:\n",
        "            predicted_indices = predicted_indices.unsqueeze(0)\n",
        "\n",
        "        predicted_tokens = tokenizer.convert_ids_to_tokens(predicted_indices[0].tolist())\n",
        "\n",
        "        result_tokens = [\n",
        "            predicted_tokens[i] if masked_tokens[i] == tokenizer.mask_token else masked_tokens[i]\n",
        "            for i in range(len(masked_tokens))\n",
        "        ]\n",
        "\n",
        "        new_text = tokenizer.convert_tokens_to_string(result_tokens)\n",
        "        augmented_samples.append({\n",
        "            \"orig_idx\": idx,\n",
        "            \"text_original\": text,\n",
        "            \"text_augmentada\": new_text\n",
        "        })\n",
        "\n",
        "    return augmented_samples\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Carregar dataset\n",
        "# ============================================================\n",
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "augmented_rows = []\n",
        "\n",
        "# Itera sobre cada linha do treino\n",
        "for idx, row in tqdm(train_df.iterrows(), total=len(train_df)):\n",
        "    # Gera novas vers√µes da frase\n",
        "    new_samples = mlm_augment(\n",
        "        text=row[\"text\"],\n",
        "        idx=idx,           # √≠ndice original da linha no treino\n",
        "        prob=0.20,         # 15% das palavras mascaradas\n",
        "        n_aug=5            # duas vers√µes aumentadas por frase\n",
        "    )\n",
        "\n",
        "    # Adiciona resultados ao dataset final\n",
        "    for sample in new_samples:\n",
        "        new_text = sample[\"text_augmentada\"]\n",
        "\n",
        "        augmented_rows.append({\n",
        "            \"orig_idx\": sample[\"orig_idx\"],\n",
        "            \"text_original\": sample[\"text_original\"],\n",
        "            \"text_augmentada\": new_text,\n",
        "            \"class\": row[\"class\"]\n",
        "        })\n",
        "\n",
        "# Cria DataFrame com os textos aumentados\n",
        "df_aug_2 = pd.DataFrame(augmented_rows)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:47:59.171735Z",
          "iopub.execute_input": "2025-11-01T18:47:59.172414Z",
          "iopub.status.idle": "2025-11-01T18:51:49.06721Z",
          "shell.execute_reply.started": "2025-11-01T18:47:59.172392Z",
          "shell.execute_reply": "2025-11-01T18:51:49.066479Z"
        },
        "id": "915sAwIf21tT",
        "outputId": "3020b681-4d93-48eb-a2f9-5852bdc8aa53"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "‚úÖ Modelo carregado no dispositivo: cuda\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5322/5322 [03:49<00:00, 23.21it/s]\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_aug_2= df_aug_2[[\"text_augmentada\", \"class\"]].rename(columns={\"text_augmentada\": \"text\"})\n",
        "\n",
        "print(df_aug_2.shape)\n",
        "df_aug_2.head()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:53:08.757941Z",
          "iopub.execute_input": "2025-11-01T18:53:08.758251Z",
          "iopub.status.idle": "2025-11-01T18:53:08.770957Z",
          "shell.execute_reply.started": "2025-11-01T18:53:08.758227Z",
          "shell.execute_reply": "2025-11-01T18:53:08.770204Z"
        },
        "id": "L1V2B3AV21tU",
        "outputId": "f828cf2e-fe21-49ae-c786-b07ff66f77e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "(26610, 2)\n",
          "output_type": "stream"
        },
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                      text  class\n0  Parab√©ns meu presidente      0\n1         Parab√©ns meu meu      0\n2   Parab√©ns√©ns presidente      0\n3         Parab√©ns meu meu      0\n4   Parab√©ns√©ns presidente      0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Parab√©ns meu presidente</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Parab√©ns meu meu</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Parab√©ns√©ns presidente</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Parab√©ns meu meu</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Parab√©ns√©ns presidente</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "test_path = \"/kaggle/input/treinamento-e-teste/test_df.csv\"\n",
        "\n",
        "# Carregar datasets\n",
        "train_df = pd.read_csv(train_path)\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "train_final = pd.concat([train_df, df_aug_2], ignore_index=True)\n",
        "\n",
        "#  Renomear 'class' ‚Üí 'labels'\n",
        "train_final = train_final.rename(columns={\"class\": \"labels\"})\n",
        "test_df = test_df.rename(columns={\"class\": \"labels\"})\n",
        "\n",
        "\n",
        "train_final = train_final[~train_final[\"text\"].str.contains(r\"\\[UNK\\]\", regex=True, na=False)]\n",
        "train_final = train_final.drop_duplicates(subset=[\"text\"], keep=\"first\").reset_index(drop=True)\n",
        "\n",
        "#  Remover nulos e garantir tipo string\n",
        "for name, df_ in {\"train\": train_final, \"test\": test_df}.items():\n",
        "    df_.dropna(subset=[\"text\", \"labels\"], inplace=True)\n",
        "    df_[\"text\"] = df_[\"text\"].astype(str)\n",
        "    df_.loc[df_[\"text\"].str.strip() == \"\", \"text\"] = np.nan\n",
        "    df_.dropna(subset=[\"text\"], inplace=True)\n",
        "    print(f\" {name}: {len(df_)} linhas\")\n",
        "\n",
        "#  Tokeniza√ß√£o\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "train_dataset = Dataset.from_pandas(train_final)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "# ============================================================\n",
        "# 9 Treinamento e avalia√ß√£o\n",
        "# ============================================================\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=50\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "metrics = trainer.evaluate()\n",
        "print(metrics)\n",
        "\n",
        "# ============================================================\n",
        "# 9. An√°lise de Erros\n",
        "# ============================================================\n",
        "preds_output = trainer.predict(test_dataset)\n",
        "preds = np.argmax(preds_output.predictions, axis=1)\n",
        "\n",
        "result_df = test_df.copy()\n",
        "result_df[\"preds\"] = preds\n",
        "\n",
        "total = len(result_df)\n",
        "acertos = (result_df[\"labels\"] == result_df[\"preds\"]).sum()\n",
        "erros = total - acertos\n",
        "fp = ((result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)).sum()\n",
        "fn = ((result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)).sum()\n",
        "\n",
        "print(f\"\\n=== RESULTADOS DE ERRO ===\")\n",
        "print(f\"Total: {total}\")\n",
        "print(f\" Acertos: {acertos}\")\n",
        "print(f\" Erros: {erros}\")\n",
        "print(f\"  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): {fp}\")\n",
        "print(f\"  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): {fn}\")\n",
        "\n",
        "# Mostrar exemplos\n",
        "falsos_positivos = result_df[(result_df[\"preds\"] == 1) & (result_df[\"labels\"] == 0)]\n",
        "falsos_negativos = result_df[(result_df[\"preds\"] == 0) & (result_df[\"labels\"] == 1)]\n",
        "\n",
        "print(\"\\n===  FALSOS POSITIVOS ===\")\n",
        "for t in falsos_positivos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)\n",
        "\n",
        "print(\"\\n===  FALSOS NEGATIVOS ===\")\n",
        "for t in falsos_negativos[\"text\"].head(30):\n",
        "    print(\"‚Ä¢\", t)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T18:54:20.285864Z",
          "iopub.execute_input": "2025-11-01T18:54:20.28641Z",
          "iopub.status.idle": "2025-11-01T19:02:05.172092Z",
          "shell.execute_reply.started": "2025-11-01T18:54:20.286386Z",
          "shell.execute_reply": "2025-11-01T19:02:05.171407Z"
        },
        "colab": {
          "referenced_widgets": [
            "c2eca925833143a299ebeaeaa2615514",
            "d5d23e0a3f244c70b6a7b957ee4dc65b"
          ]
        },
        "id": "jAZFn5u221tU",
        "outputId": "78c7f3db-7e91-40d6-b04d-1230f6795dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": " train: 24088 linhas\n test: 1331 linhas\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/24088 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2eca925833143a299ebeaeaa2615514"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5d23e0a3f244c70b6a7b957ee4dc65b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/3267608434.py:68: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.5505, 'grad_norm': 1.7914618253707886, 'learning_rate': 1.9349269588313415e-05, 'epoch': 0.033200531208499334}\n{'loss': 0.3775, 'grad_norm': 9.333806037902832, 'learning_rate': 1.868525896414343e-05, 'epoch': 0.06640106241699867}\n{'loss': 0.3199, 'grad_norm': 10.904051780700684, 'learning_rate': 1.8021248339973442e-05, 'epoch': 0.099601593625498}\n{'loss': 0.2919, 'grad_norm': 16.351192474365234, 'learning_rate': 1.7357237715803456e-05, 'epoch': 0.13280212483399734}\n{'loss': 0.2494, 'grad_norm': 2.6490745544433594, 'learning_rate': 1.669322709163347e-05, 'epoch': 0.16600265604249667}\n{'loss': 0.2621, 'grad_norm': 1.1895049810409546, 'learning_rate': 1.602921646746348e-05, 'epoch': 0.199203187250996}\n{'loss': 0.2262, 'grad_norm': 15.565313339233398, 'learning_rate': 1.5365205843293494e-05, 'epoch': 0.23240371845949534}\n{'loss': 0.2849, 'grad_norm': 11.781869888305664, 'learning_rate': 1.4701195219123507e-05, 'epoch': 0.2656042496679947}\n{'loss': 0.2267, 'grad_norm': 12.089874267578125, 'learning_rate': 1.4037184594953521e-05, 'epoch': 0.29880478087649404}\n{'loss': 0.2491, 'grad_norm': 3.8329055309295654, 'learning_rate': 1.3373173970783533e-05, 'epoch': 0.33200531208499334}\n{'loss': 0.2498, 'grad_norm': 11.269783973693848, 'learning_rate': 1.2709163346613547e-05, 'epoch': 0.3652058432934927}\n{'loss': 0.2633, 'grad_norm': 12.623608589172363, 'learning_rate': 1.204515272244356e-05, 'epoch': 0.398406374501992}\n{'loss': 0.1941, 'grad_norm': 6.180527210235596, 'learning_rate': 1.1381142098273574e-05, 'epoch': 0.4316069057104914}\n{'loss': 0.2496, 'grad_norm': 6.683557510375977, 'learning_rate': 1.0717131474103586e-05, 'epoch': 0.4648074369189907}\n{'loss': 0.2186, 'grad_norm': 7.223577976226807, 'learning_rate': 1.00531208499336e-05, 'epoch': 0.49800796812749004}\n{'loss': 0.2016, 'grad_norm': 7.501114845275879, 'learning_rate': 9.389110225763613e-06, 'epoch': 0.5312084993359893}\n{'loss': 0.1899, 'grad_norm': 23.263269424438477, 'learning_rate': 8.725099601593626e-06, 'epoch': 0.5644090305444888}\n{'loss': 0.2031, 'grad_norm': 6.040908336639404, 'learning_rate': 8.06108897742364e-06, 'epoch': 0.5976095617529881}\n{'loss': 0.1742, 'grad_norm': 12.159980773925781, 'learning_rate': 7.397078353253653e-06, 'epoch': 0.6308100929614874}\n{'loss': 0.2133, 'grad_norm': 7.509305953979492, 'learning_rate': 6.733067729083666e-06, 'epoch': 0.6640106241699867}\n{'loss': 0.1941, 'grad_norm': 3.5166525840759277, 'learning_rate': 6.0690571049136795e-06, 'epoch': 0.6972111553784861}\n{'loss': 0.1567, 'grad_norm': 22.135112762451172, 'learning_rate': 5.405046480743692e-06, 'epoch': 0.7304116865869854}\n{'loss': 0.233, 'grad_norm': 4.167379379272461, 'learning_rate': 4.741035856573706e-06, 'epoch': 0.7636122177954847}\n{'loss': 0.1418, 'grad_norm': 23.70310401916504, 'learning_rate': 4.077025232403719e-06, 'epoch': 0.796812749003984}\n{'loss': 0.1723, 'grad_norm': 2.30618953704834, 'learning_rate': 3.4130146082337318e-06, 'epoch': 0.8300132802124834}\n{'loss': 0.1765, 'grad_norm': 18.342378616333008, 'learning_rate': 2.749003984063745e-06, 'epoch': 0.8632138114209827}\n{'loss': 0.12, 'grad_norm': 3.4730865955352783, 'learning_rate': 2.0849933598937588e-06, 'epoch': 0.896414342629482}\n{'loss': 0.1943, 'grad_norm': 21.96500587463379, 'learning_rate': 1.4209827357237718e-06, 'epoch': 0.9296148738379814}\n{'loss': 0.1246, 'grad_norm': 5.717872619628906, 'learning_rate': 7.569721115537849e-07, 'epoch': 0.9628154050464808}\n{'loss': 0.1542, 'grad_norm': 2.4965696334838867, 'learning_rate': 9.296148738379815e-08, 'epoch': 0.9960159362549801}\n{'eval_loss': 0.29196697473526, 'eval_accuracy': 0.9166040570999249, 'eval_precision': 0.9154302670623146, 'eval_recall': 0.9195230998509687, 'eval_f1': 0.9174721189591077, 'eval_runtime': 7.2652, 'eval_samples_per_second': 183.201, 'eval_steps_per_second': 11.562, 'epoch': 1.0}\n{'train_runtime': 440.7484, 'train_samples_per_second': 54.652, 'train_steps_per_second': 3.417, 'train_loss': 0.22852378941152202, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.29196697473526, 'eval_accuracy': 0.9166040570999249, 'eval_precision': 0.9154302670623146, 'eval_recall': 0.9195230998509687, 'eval_f1': 0.9174721189591077, 'eval_runtime': 7.5798, 'eval_samples_per_second': 175.598, 'eval_steps_per_second': 11.082, 'epoch': 1.0}\n{'eval_loss': 0.29196697473526, 'eval_accuracy': 0.9166040570999249, 'eval_precision': 0.9154302670623146, 'eval_recall': 0.9195230998509687, 'eval_f1': 0.9174721189591077, 'eval_runtime': 7.5798, 'eval_samples_per_second': 175.598, 'eval_steps_per_second': 11.082, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\n=== RESULTADOS DE ERRO ===\nTotal: 1331\n Acertos: 1220\n Erros: 111\n  ‚Ü≥ Falsos Positivos (prev√™ ofensa mas n√£o √©): 57\n  ‚Ü≥ Falsos Negativos (n√£o detectou ofensa real): 54\n\n===  FALSOS POSITIVOS ===\n‚Ä¢ Cada dia se queimando mais\n‚Ä¢ √â a treva.\n‚Ä¢ Isto mesmo. Esses filhos do Sr. Presidente deveriam ficar mais falados. V√£o colocar tudo a perder. Uma l√°stima.\n‚Ä¢ Jesus, √© cada uma desse cidad√£o. √â de assustar.\n‚Ä¢ SENSACIONAL √â BEM P√îR AI MESMOOO, ELE EST√Å PREOCUPADO PORQU√ä SERA, QUEM √ë DEVE √ë TEME, SIMPLES ASSIM!!!\n‚Ä¢ O Brasil lutando para sair da Grota e alguns preocupado com a tal de Greta. Vamos ficar at√© quando nessa?\n‚Ä¢ Aro\n‚Ä¢ A t√° ,a esquerda pode falar que vai incendiar o pa√≠s e ningu√©m fala nada.\n‚Ä¢ E n√≥s que podemos ter perdido uma Greta Thunberg cruelmente assasinada por witizelassassino witizelgenocida. √Åghata nossa Menina Maravilha tinha apenas 8 anos seu discurso era apenas a boneca M√¥nica, mas quem poder√° afirmar ao contr√°rio que aos 16 anos trocaria M√¥nica pela bandeira de um mundo mais justo e sustent√°vel.\n‚Ä¢ Nem era pra ter sido preso! LulaInocente\n‚Ä¢ Quando n√£o tem roubo melhora tudo\n‚Ä¢ Uma menina chega as capas aos 16 anos e n√£o s√£o em p√°ginas policiais,muito contr√°rio dos pol√≠ticos desse pa√≠s que s√≥ faz vergonha ao inv√©s de cumprir seus mandados e os objetivos e promessas de melhoras. N√≥s fizemos a nossa parte,tiramos um governo corrupto do trono,agora quem t√° l√° abre a boca e fala merda. S√≥ lembrando que n√≥s TIRAMOS e COLOCAMOS vcs,N√≥s o POVO.\n‚Ä¢ Bene disse tudo. Esse ign√≥bil faltou aulas de Hist√≥ria.\n‚Ä¢ Deixando de seguir, pq so perde tempo implicando com os bolsonaros...3...2..1...fui!\n‚Ä¢ Meu amigo.. pol√≠tica n√£o √© pra fracos n√£o... Meu amigo √© muita treta. Tamb√©m, enquanto os sal√°rios forem altos ter√° at√© mortes, como tem. Era pra ser sal√°rio de professor isso a√≠\n‚Ä¢ So negros morrem no Brasil? Bandido nao escolhe cor!\n‚Ä¢ acho que esse, menininho odeia o pai. s√≥ faz M.\n‚Ä¢ E tem gado do bozo q ainda aplaude!\n‚Ä¢ Deveria ter pena da Venezuela !!!!\n‚Ä¢ E direitos, fora bolsonaro\n‚Ä¢ haddad e freixo futuro do brasil\n‚Ä¢ Ela deveria dizer. T√î PREOCUPADA COM A LAVA JATO DO BRASIL NA MINHA COLA\n‚Ä¢ Abra um col√©gio militar em S√£o Gabriel da Cachoeira, na cabe√ßa do Cachorro!! Precisa muito!!!\n‚Ä¢ Que horror!\n‚Ä¢ Para de progudicar o governo parem de botar leinha na fogueira, so demora afala mas quando falam sai fais por todo lado !!!\n‚Ä¢ Sou bolsonarista at√© debaixo d√°gua, vou votar nele novamente se for candidato √† reelei√ß√£o, mas os filhos do presidente precisam realmente colocar filtro na boca. Isso demonstra um pouco de imaturidade pol√≠tica dos mesmos. Mas vamos l√°. BOLSONARO 2022 com certeza.\n‚Ä¢ Patroc√≠nio da esquerda internacional , n√£o tem fim a verba.\n‚Ä¢ O q fortalece a esquerda s√£o os traidores q se elegeram as custas do presidente e depois de eleitos o apunhalam pelas costas. Isso sim!!!\n‚Ä¢ Eita ferro,kkkkk\n‚Ä¢ Nesse meio ronda energias ruins e pessoas m√°s, SO orando pedindo for√ßas dos c√©us, SO DEUS pra derrubar essas trevas.\n\n===  FALSOS NEGATIVOS ===\n‚Ä¢ Tem que prender por incita√ß√£o a viol√™ncia.\n‚Ä¢ Faz me rir!!!\n‚Ä¢ Cuidado ao defender uma militante de esquerda. Ela se apegou a uma causa que nao tem solu√ßao. H√° muito por tras da far√ßa que ela se exp√µe.\n‚Ä¢ Incompetente ela sempre foi!\n‚Ä¢ Terrorismo, al√©m do preconceito contra RORAIMA\n‚Ä¢ Isso √© um arrast√£o?\n‚Ä¢ Parece que se a mulher √© de direita ela n√£o merece ser respeitada segundo jornais de Esquerda, pois n√£o hesitaram nem um minuto em massacrar a mulher\n‚Ä¢ Sra Leilane repita comigo por favor por v√°rias vezes !! ME FUDI !!!!! Kkkkk\n‚Ä¢ Fodase.\n‚Ä¢ O que √© dela t√° guardado\n‚Ä¢ As pessoas normais e que ainda t√™m capacidade de ver e entender o que est√° acontecendo\n‚Ä¢ .zambelli eu gosto do seu trabalho e adimiro voc√™, o melhor rem√©dio ignore a Joicehasselmann, ela n√£o merece perda de tempo com ela, j√° est√° acabada!!!\n‚Ä¢ Vou filosofar O coc√¥ sai pelo √¢nus, mas pelo jeito, em algumas pessoas do congresso, se acumula no c√©rebro\n‚Ä¢ Deviamos invadir o insta dessa carta capital e falar oq eles merecem ler...senti a ang√∫stia nas palavras da ministra Damares...estou contigo\n‚Ä¢ Pessoal , vamos nos unir sempre. Kim e MBL s√£o nossos aliados. A esquerda deste pa√≠s se junta e n√£o t√™m car√°ter. Ponto. A direita precisa ser firme. Um ou outro ponto poder√° ser divergido. Normal. Conversem. DIREITA sempre. Unidos √© que vencemos eles. Kim √© um pol√≠tico honesto. Ele s√≥ precisa ter maldade. E sair do DEM. Claro\n‚Ä¢ Esse cara vai furde com trabalhador brasileiro quem votou nesse cara t√° lacado kkkkkkk\n‚Ä¢ duas notas de 3\n‚Ä¢ Vamos trabalhar? Ficar de picuinha n√£o vai ajudar o Brasil, esquece essa cobra e siga em frente.\n‚Ä¢ N√£o entendo. Por que n√£o o prenderam imediatamente por incita√ß√£o √† viol√™ncia? Quanto mais tempo ele passar livre, pior para a Na√ß√£o!\n‚Ä¢ Incitando o √≥dio a guerra ,vandalismo\n‚Ä¢ Voc√™s ainda n√£o entenderam a extrema esquerda revolucion√°ria voc√™ falando ou n√£o, fazendo ou n√£o, produzindo ou n√£o, atacando ou n√£o, se defendendo ou n√£o, eles querem o poder acima de tudo, onde o fim nustifica os meios. V√£o atacar violentamente e sistematicamente tudo aquilo que est√° fora dos interesses do partido. Isso √© um fato hist√≥rico. S√≥ no Brasil que enxergam a esquerda como um partido, quando a hist√≥ria nos prova o contr√°rio. N√£o √© uma quest√£o de dar muni√ß√£o para o oponente, e sim, de sobrevivencia em meio a uma m√°fia pol√≠tica criminosa que tomou conta o estamento burocr√°tico brasileiro, que se preciso for, mandam matar. Algu√©m ainda tem d√∫vidas?\n‚Ä¢ O √≥dio da esquerda √© maior que o seu amor pelo Brasil, vale at√© quebrar o pa√≠s se isso prejudicar o Bolsonaro, n√£o importa se o brasileiro se FODE junto, importante √© que atrapalharam o Bolsonaro!!\n‚Ä¢ Marquinho que parece gostar do verbo espancar, mmm?\n‚Ä¢ Cortei in√∫meras p√°ginas que n√£o √© oficial, tem comunista que entra nesses grupos que fazem campanha at√© para n√£o comer carne, √© bom a√≠ sobra e os produtores exportam mais ,E a greve segunda feira?.\n‚Ä¢ LULU e JOYCI TRAIDORES JUDAS SATAN√ÅS\n‚Ä¢ Isto sempre ficou muito claro, Bolsolixo √© contra os trabalhadores e o povo de bem num modo geral, ele ap√≥ia os milicianos, pronto a fazer qualquer desgra√ßa contra o povo.\n‚Ä¢ Na terra em que essa mulher africana √© bonita as trans s√£o mulheres. Surrealismo cl√°ssico.\n‚Ä¢ A rainha das fake News ataca de novo\n‚Ä¢ Deputada para com isso admiro seu trabalho mas essa menina tem q parar com isso muita pessoas dando moral a essa garota q se faz de Santa acho q vc esta ao lado dela ... Sou f√£ da senhora mas n√£o juga o presidente n√£o\n‚Ä¢ Ou derruba esse congresso e STF ou o Brasil ser√° derrubado.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Garantir que stopwords est√£o dispon√≠veis\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
        "\n",
        "# Carrega modelo SBERT (para medir similaridade sem√¢ntica)\n",
        "sbert = SentenceTransformer('/kaggle/input/miniml/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "\n",
        "def debug_mlm_augment_conditional_one_token_dataset(\n",
        "    text,\n",
        "    tokenizer,\n",
        "    model,\n",
        "    device,\n",
        "    n_aug=10,\n",
        "    top_k=10,\n",
        "    max_tries=20,\n",
        "    min_similarity=0.7\n",
        "):\n",
        "    \"\"\"\n",
        "    Vers√£o com debug detalhado do gerador de augmentations via MLM.\n",
        "    Mostra cada tentativa, similaridade e motivo de rejei√ß√£o.\n",
        "    \"\"\"\n",
        "\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    augmented_samples = []\n",
        "\n",
        "    print(\"=\" * 100)\n",
        "    print(f\"üìù Texto original: {text}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    # Limpeza b√°sica\n",
        "    text = re.sub(r\"[‚Äò‚Äô]\", \"'\", text)\n",
        "    text = re.sub(r\"[‚Äú‚Äù]\", '\"', text)\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    if len(tokens) < 3:\n",
        "        print(\" Frase muito curta (menos de 3 tokens).\")\n",
        "        print(\"=\" * 100)\n",
        "        return []\n",
        "\n",
        "    def is_full_word(tokens, idx):\n",
        "        \"\"\"True se token for palavra completa, n√£o subpalavra.\"\"\"\n",
        "        if tokens[idx].startswith(\"##\"):\n",
        "            return False\n",
        "        if idx + 1 < len(tokens) and tokens[idx + 1].startswith(\"##\"):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    candidate_indices = [\n",
        "        i for i, t in enumerate(tokens)\n",
        "        if t.isalpha() and is_full_word(tokens, i) and t.lower() not in stop_words\n",
        "    ]\n",
        "\n",
        "    if not candidate_indices:\n",
        "        print(\" Nenhuma palavra candidata para mascarar.\")\n",
        "        print(\"=\" * 100)\n",
        "        return []\n",
        "\n",
        "    print(f\" Tokens candidatos ({len(candidate_indices)}): {[tokens[i] for i in candidate_indices]}\")\n",
        "\n",
        "    # Embedding do texto original\n",
        "    orig_emb = sbert.encode(text, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "    tries = 0\n",
        "    total_attempts = 0\n",
        "    while len(augmented_samples) < n_aug and tries < max_tries:\n",
        "        tries += 1\n",
        "\n",
        "        mask_idx = random.choice(candidate_indices)\n",
        "        masked_tokens = tokens.copy()\n",
        "        masked_tokens[mask_idx] = tokenizer.mask_token\n",
        "        masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "\n",
        "        inputs = tokenizer(masked_text, return_tensors=\"pt\").to(device)\n",
        "        mask_positions = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=False)\n",
        "        if mask_positions.size(0) == 0:\n",
        "            print(\" Nenhum [MASK] encontrado ap√≥s tokeniza√ß√£o.\")\n",
        "            continue\n",
        "        mask_pos = mask_positions[0, 1].item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits[0, mask_pos]\n",
        "        top_k_ids = torch.topk(logits, k=min(top_k, logits.size(0))).indices.tolist()\n",
        "        random.shuffle(top_k_ids)\n",
        "\n",
        "        for chosen_id in top_k_ids:\n",
        "            total_attempts += 1\n",
        "            new_token = tokenizer.convert_ids_to_tokens([chosen_id])[0]\n",
        "            if new_token == \"[UNK]\" or new_token.startswith(\"##\"):\n",
        "                print(f\" Rejeitado: token inv√°lido ({new_token})\")\n",
        "                continue\n",
        "\n",
        "            new_tokens = tokens.copy()\n",
        "            new_tokens[mask_idx] = new_token\n",
        "            new_text = tokenizer.convert_tokens_to_string(new_tokens).strip()\n",
        "\n",
        "            if \"[UNK]\" in new_text:\n",
        "                print(f\" Rejeitado: cont√©m [UNK] ‚Üí {new_text}\")\n",
        "                continue\n",
        "\n",
        "            if new_text.lower() == text.strip().lower():\n",
        "                print(f\" Rejeitado: igual ao original ‚Üí {new_text}\")\n",
        "                continue\n",
        "\n",
        "            # Calcula similaridade\n",
        "            new_emb = sbert.encode(new_text, convert_to_tensor=True, show_progress_bar=False)\n",
        "            sim = util.cos_sim(orig_emb, new_emb).item()\n",
        "\n",
        "            if sim < min_similarity:\n",
        "                print(f\" Rejeitado (sim={sim:.3f} < {min_similarity}) ‚Üí {new_text}\")\n",
        "                continue\n",
        "\n",
        "            if new_text in augmented_samples:\n",
        "                print(f\" J√° gerado ‚Üí {new_text}\")\n",
        "                continue\n",
        "\n",
        "            augmented_samples.append(new_text)\n",
        "            print(f\"‚úÖ Aceito (sim={sim:.3f}) ‚Üí {new_text}\")\n",
        "\n",
        "            if len(augmented_samples) >= n_aug:\n",
        "                break\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(f\" Total aceitas: {len(augmented_samples)} / {n_aug} (em {total_attempts} tentativas)\")\n",
        "    print(\"=\" * 100)\n",
        "    return augmented_samples\n",
        "\n",
        "\n",
        "# Exemplo de uso com seu dataset\n",
        "import pandas as pd\n",
        "\n",
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "for i, row in train_df.head(50).iterrows():\n",
        "    novas = debug_mlm_augment_conditional_one_token_dataset(\n",
        "        text=row[\"text\"],\n",
        "        tokenizer=tokenizer,\n",
        "        model=model,\n",
        "        device=device,\n",
        "        n_aug=10,\n",
        "        top_k=10,\n",
        "        max_tries=20,\n",
        "        min_similarity=0.7,\n",
        "    )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T19:52:12.411442Z",
          "iopub.execute_input": "2025-11-01T19:52:12.412059Z",
          "iopub.status.idle": "2025-11-01T19:52:33.53558Z",
          "shell.execute_reply.started": "2025-11-01T19:52:12.412021Z",
          "shell.execute_reply": "2025-11-01T19:52:33.534791Z"
        },
        "id": "enaHSM4C21tU",
        "outputId": "d182c691-04aa-4838-c702-3e81c9ae1291"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "====================================================================================================\nüìù Texto original: Parab√©ns meu presidente\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['presidente']\n‚úÖ Aceito (sim=0.715) ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n‚úÖ Aceito (sim=0.725) ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n‚úÖ Aceito (sim=0.743) ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu !\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu caro\n J√° gerado ‚Üí Parab√©ns meu !\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu caro\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n J√° gerado ‚Üí Parab√©ns meu !\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu caro\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu .\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n J√° gerado ‚Üí Parab√©ns meu caro\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.591 < 0.7) ‚Üí Parab√©ns meu cora√ß√£o\n J√° gerado ‚Üí Parab√©ns meu caro\n Rejeitado (sim=0.688 < 0.7) ‚Üí Parab√©ns meu filho\n Rejeitado (sim=0.624 < 0.7) ‚Üí Parab√©ns meu irm√£o\n Rejeitado (sim=0.671 < 0.7) ‚Üí Parab√©ns meu amigo\n Rejeitado (sim=0.655 < 0.7) ‚Üí Parab√©ns meu amor\n J√° gerado ‚Üí Parab√©ns meu .\n Rejeitado (sim=0.664 < 0.7) ‚Üí Parab√©ns meu pai\n J√° gerado ‚Üí Parab√©ns meu !\n Rejeitado (sim=0.680 < 0.7) ‚Üí Parab√©ns meu neto\n----------------------------------------------------------------------------------------------------\n Total aceitas: 3 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Valeu seu analise.\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: PT roubando o pa√≠s inteiro!!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['PT', 'pa√≠s', 'inteiro']\n‚úÖ Aceito (sim=0.895) ‚Üí PT roubando o pa√≠s . ! !\n‚úÖ Aceito (sim=0.882) ‚Üí PT roubando o pa√≠s ? ! !\n‚úÖ Aceito (sim=0.913) ‚Üí PT roubando o pa√≠s inteiro ! !\n‚úÖ Aceito (sim=0.907) ‚Üí PT roubando o pa√≠s todo ! !\n‚úÖ Aceito (sim=0.875) ‚Üí PT roubando o pa√≠s j√° ! !\n‚úÖ Aceito (sim=0.880) ‚Üí PT roubando o pa√≠s mesmo ! !\n‚úÖ Aceito (sim=0.889) ‚Üí PT roubando o pa√≠s ! ! !\n Rejeitado (sim=0.681 < 0.7) ‚Üí PT roubando o pa√≠s brasileiro ! !\n Rejeitado: token inv√°lido ([UNK])\n‚úÖ Aceito (sim=0.888) ‚Üí PT roubando o pa√≠s tamb√©m ! !\n‚úÖ Aceito (sim=0.813) ‚Üí PT roubando o Estado inteiro ! !\n‚úÖ Aceito (sim=0.792) ‚Üí PT roubando o mundo inteiro ! !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 12 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Lula livre.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['Lula', 'livre']\n Rejeitado (sim=0.426 < 0.7) ‚Üí Mercado livre .\n Rejeitado (sim=0.304 < 0.7) ‚Üí Software livre .\n Rejeitado (sim=0.482 < 0.7) ‚Üí Acesso livre .\n Rejeitado (sim=0.437 < 0.7) ‚Üí √â livre .\n Rejeitado (sim=0.293 < 0.7) ‚Üí Som livre .\n Rejeitado (sim=0.492 < 0.7) ‚Üí Campo livre .\n Rejeitado (sim=0.443 < 0.7) ‚Üí Ar livre .\n Rejeitado (sim=0.476 < 0.7) ‚Üí Tempo livre .\n Rejeitado (sim=0.429 < 0.7) ‚Üí Espa√ßo livre .\n Rejeitado (sim=0.373 < 0.7) ‚Üí Jogo livre .\n‚úÖ Aceito (sim=0.871) ‚Üí Lula ) .\n‚úÖ Aceito (sim=0.819) ‚Üí Lula disse .\n‚úÖ Aceito (sim=0.802) ‚Üí Lula respondeu .\n‚úÖ Aceito (sim=0.816) ‚Üí Lula n√£o .\n‚úÖ Aceito (sim=0.731) ‚Üí Lula sabia .\n‚úÖ Aceito (sim=0.714) ‚Üí Lula concordou .\n‚úÖ Aceito (sim=0.880) ‚Üí Lula \" .\n‚úÖ Aceito (sim=0.704) ‚Üí Lula venceu .\n‚úÖ Aceito (sim=0.746) ‚Üí Lula concorda .\n‚úÖ Aceito (sim=0.862) ‚Üí Lula tamb√©m .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 20 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Ele esqueceu de amadurecer\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Agrade√ßa ao japa\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Saber que um dia j√° ouvi prega√ß√£o desse irm√£o e me senti aben√ßoado. Agr prega e vive nesse odio\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (7): ['dia', 'ouvi', 'desse', 'irm√£o', 'senti', 'vive', 'nesse']\n‚úÖ Aceito (sim=0.843) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse pastor e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.794) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse tipo e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.767) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse nome e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.792) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse jeito e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.778) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse n√≠vel e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.772) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse livro e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.855) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse senhor e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.795) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse Deus e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.774) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse g√™nero e me senti aben√ßoado . Agr prega e vive nesse odio\n‚úÖ Aceito (sim=0.777) ‚Üí Saber que um dia j√° ouvi prega√ß√£o desse povo e me senti aben√ßoado . Agr prega e vive nesse odio\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: M√≥ cara de cu essa mulher ficou depois\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (4): ['cara', 'cu', 'mulher', 'ficou']\n‚úÖ Aceito (sim=0.720) ‚Üí M√≥ cara de cu essa foto ficou depois\n Rejeitado: igual ao original ‚Üí M√≥ cara de cu essa mulher ficou depois\n Rejeitado (sim=0.674 < 0.7) ‚Üí M√≥ cara de cu essa imagem ficou depois\n‚úÖ Aceito (sim=0.808) ‚Üí M√≥ cara de cu essa aqui ficou depois\n‚úÖ Aceito (sim=0.804) ‚Üí M√≥ cara de cu essa que ficou depois\n‚úÖ Aceito (sim=0.810) ‚Üí M√≥ cara de cu essa cara ficou depois\n‚úÖ Aceito (sim=0.897) ‚Üí M√≥ cara de cu essa menina ficou depois\n‚úÖ Aceito (sim=0.945) ‚Üí M√≥ cara de cu essa ela ficou depois\n‚úÖ Aceito (sim=0.768) ‚Üí M√≥ cara de cu essa coisa ficou depois\n‚úÖ Aceito (sim=0.751) ‚Üí M√≥ cara de cu essa cena ficou depois\n‚úÖ Aceito (sim=0.924) ‚Üí M√≥ cara de cu essa mulher falou depois\n‚úÖ Aceito (sim=0.949) ‚Üí M√≥ cara de cu essa mulher disse depois\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 12 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Bandido gay enrustido! Ped√≥filo de merda!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['gay']\n‚úÖ Aceito (sim=0.814) ‚Üí Bandido totalmente enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.803) ‚Üí Bandido , enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.822) ‚Üí Bandido e enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.818) ‚Üí Bandido do enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.821) ‚Üí Bandido de enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.994) ‚Üí Bandido gay enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.819) ‚Üí Bandido - enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.779) ‚Üí Bandido √© enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.823) ‚Üí Bandido mais enrustido ! Ped√≥filo de merda !\n‚úÖ Aceito (sim=0.815) ‚Üí Bandido muito enrustido ! Ped√≥filo de merda !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Greg√≥rio √© uma das pessoas mais l√∫cidas e inteligentes que conhe√ßo.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['Greg√≥rio', 'pessoas']\n‚úÖ Aceito (sim=0.872) ‚Üí Greg√≥rio √© uma das hist√≥rias mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.956) ‚Üí Greg√≥rio √© uma das criaturas mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.989) ‚Üí Greg√≥rio √© uma das personalidades mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=1.000) ‚Üí Greg√≥rio √© uma das pessoas mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.969) ‚Üí Greg√≥rio √© uma das figuras mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.971) ‚Üí Greg√≥rio √© uma das coisas mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.924) ‚Üí Greg√≥rio √© uma das personagens mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.910) ‚Üí Greg√≥rio √© uma das vozes mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.875) ‚Üí Greg√≥rio √© uma das crian√ßas mais l√∫cidas e inteligentes que conhe√ßo .\n‚úÖ Aceito (sim=0.868) ‚Üí Greg√≥rio √© uma das mulheres mais l√∫cidas e inteligentes que conhe√ßo .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Palavras de moleque\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: NOJO!!!!!!!!!!!!!!!\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Essa Globo √© uma bosta\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['Globo']\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.393 < 0.7) ‚Üí Essa empresa √© uma bosta\n Rejeitado (sim=0.398 < 0.7) ‚Üí Essa revista √© uma bosta\n Rejeitado (sim=0.531 < 0.7) ‚Üí Essa mina √© uma bosta\n Rejeitado (sim=0.337 < 0.7) ‚Üí Essa novela √© uma bosta\n Rejeitado (sim=0.508 < 0.7) ‚Üí Essa mulher √© uma bosta\n Rejeitado (sim=0.330 < 0.7) ‚Üí Essa cidade √© uma bosta\n Rejeitado (sim=0.512 < 0.7) ‚Üí Essa menina √© uma bosta\n Rejeitado (sim=0.421 < 0.7) ‚Üí Essa turma √© uma bosta\n Rejeitado (sim=0.328 < 0.7) ‚Üí Essa escola √© uma bosta\n Rejeitado (sim=0.576 < 0.7) ‚Üí Essa gente √© uma bosta\n----------------------------------------------------------------------------------------------------\n Total aceitas: 0 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Lixo\n----------------------------------------------------------------------------------------------------\n Frase muito curta (menos de 3 tokens).\n====================================================================================================\n====================================================================================================\nüìù Texto original: Este cara vai acabar com o Brasil\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (4): ['cara', 'vai', 'acabar', 'Brasil']\n Rejeitado (sim=0.547 < 0.7) ‚Üí Este cara vai acabar com o governo\n Rejeitado (sim=0.452 < 0.7) ‚Üí Este cara vai acabar com o Corinthians\n Rejeitado (sim=0.676 < 0.7) ‚Üí Este cara vai acabar com o jogo\n‚úÖ Aceito (sim=0.779) ‚Üí Este cara vai acabar com o futebol\n Rejeitado: igual ao original ‚Üí Este cara vai acabar com o Brasil\n Rejeitado (sim=0.524 < 0.7) ‚Üí Este cara vai acabar com o planeta\n Rejeitado (sim=0.642 < 0.7) ‚Üí Este cara vai acabar com o mundo\n Rejeitado (sim=0.670 < 0.7) ‚Üí Este cara vai acabar com o pa√≠s\n Rejeitado (sim=0.642 < 0.7) ‚Üí Este cara vai acabar com o povo\n Rejeitado (sim=0.582 < 0.7) ‚Üí Este cara vai acabar com o PT\n‚úÖ Aceito (sim=0.858) ‚Üí Este pa√≠s vai acabar com o Brasil\n‚úÖ Aceito (sim=0.796) ‚Üí Este crime vai acabar com o Brasil\n‚úÖ Aceito (sim=0.870) ‚Üí Este partido vai acabar com o Brasil\n‚úÖ Aceito (sim=0.866) ‚Üí Este golpe vai acabar com o Brasil\n‚úÖ Aceito (sim=0.813) ‚Üí Este dinheiro vai acabar com o Brasil\n‚úÖ Aceito (sim=0.796) ‚Üí Este governo vai acabar com o Brasil\n‚úÖ Aceito (sim=0.821) ‚Üí Este circo vai acabar com o Brasil\n‚úÖ Aceito (sim=0.799) ‚Üí Este projeto vai acabar com o Brasil\n‚úÖ Aceito (sim=0.728) ‚Üí Este imposto vai acabar com o Brasil\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 19 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Eita que vai ter petistas presos a bambam.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['vai', 'ter', 'presos']\n‚úÖ Aceito (sim=0.925) ‚Üí Eita que vai ter petistas dando a bambam .\n‚úÖ Aceito (sim=0.858) ‚Üí Eita que vai ter petistas jogando a bambam .\n‚úÖ Aceito (sim=0.923) ‚Üí Eita que vai ter petistas batendo a bambam .\n Rejeitado (sim=0.667 < 0.7) ‚Üí Eita que vai ter petistas cantando a bambam .\n‚úÖ Aceito (sim=0.936) ‚Üí Eita que vai ter petistas passando a bambam .\n‚úÖ Aceito (sim=0.933) ‚Üí Eita que vai ter petistas levando a bambam .\n‚úÖ Aceito (sim=0.931) ‚Üí Eita que vai ter petistas que a bambam .\n‚úÖ Aceito (sim=0.837) ‚Üí Eita que vai ter petistas matando a bambam .\n‚úÖ Aceito (sim=0.928) ‚Üí Eita que vai ter petistas saindo a bambam .\n‚úÖ Aceito (sim=0.925) ‚Üí Eita que vai ter petistas indo a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas batendo a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas indo a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas que a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas jogando a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas passando a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas saindo a bambam .\n Rejeitado (sim=0.667 < 0.7) ‚Üí Eita que vai ter petistas cantando a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas dando a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas levando a bambam .\n J√° gerado ‚Üí Eita que vai ter petistas matando a bambam .\n‚úÖ Aceito (sim=0.916) ‚Üí Eita que vai ver petistas presos a bambam .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 21 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: S√≥ chorando\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Se o comandante n√£o respeita o povo. Eu o odeio por isso. Agora passo a odiar esse cara a√≠ protegido pelo dinheiro √≥dio e nojo.....\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (10): ['comandante', 'respeita', 'povo', 'Agora', 'passo', 'cara', 'a√≠', 'protegido', 'dinheiro', '√≥dio']\n‚úÖ Aceito (sim=0.949) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse pessoal a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.939) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse povo a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.985) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse homem a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.993) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse cara a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.977) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse rapaz a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.966) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse comandante a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.934) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse coronel a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.902) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse presidente a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.989) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse sujeito a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n‚úÖ Aceito (sim=0.981) ‚Üí Se o comandante n√£o respeita o povo . Eu o odeio por isso . Agora passo a odiar esse senhor a√≠ protegido pelo dinheiro √≥dio e nojo . . . . .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: FORA FORA FRANCA?? Ela loucura FALANDO se???? LIXO . Faltou respeitosamente para BRASIL ORGULHOSO POR CAUSA N√ÉO PODEM FALTOU RESPEITO ELA\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Que vontade de dar um abra√ßo nos dois!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['vontade', 'dar', 'dois']\n‚úÖ Aceito (sim=0.997) ‚Üí Que vontade de dar um abra√ßo nos dois !\n‚úÖ Aceito (sim=0.881) ‚Üí Que vontade de dar um abra√ßo nos meus !\n‚úÖ Aceito (sim=0.811) ‚Üí Que vontade de dar um abra√ßo nos amigos !\n‚úÖ Aceito (sim=0.884) ‚Üí Que vontade de dar um abra√ßo nos seus !\n‚úÖ Aceito (sim=0.730) ‚Üí Que vontade de dar um abra√ßo nos filhos !\n‚úÖ Aceito (sim=0.780) ‚Üí Que vontade de dar um abra√ßo nos meninos !\n‚úÖ Aceito (sim=0.774) ‚Üí Que vontade de dar um abra√ßo nos p√©s !\n‚úÖ Aceito (sim=0.820) ‚Üí Que vontade de dar um abra√ßo nos outros !\n‚úÖ Aceito (sim=0.833) ‚Üí Que vontade de dar um abra√ßo nos olhos !\n‚úÖ Aceito (sim=0.798) ‚Üí Que vontade de dar um abra√ßo nos tr√™s !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: EmPauta Andreia Sadi! Vai firme presidente...sempre defendendo a nossa soberania...estamos resgatando o Brasil que estava sendo entregue ...\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (9): ['Vai', 'firme', 'presidente', 'sempre', 'defendendo', 'soberania', 'Brasil', 'sendo', 'entregue']\n‚úÖ Aceito (sim=0.956) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . estamos defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.977) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . sempre defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.953) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . vamos defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.967) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . continua defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.971) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . vem defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.955) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . estou defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.956) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . est√£o defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.968) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . est√° defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.967) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . n√≥s defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n‚úÖ Aceito (sim=0.965) ‚Üí EmPauta Andreia Sadi ! Vai firme presidente . . . todos defendendo a nossa soberania . . . estamos resgatando o Brasil que estava sendo entregue . . .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: absurdo, porra aqui n√£o e casa de veraneio. esses parlamentares tem que ser afastados, que palha√ßada\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['aqui', 'casa', 'parlamentares']\n‚úÖ Aceito (sim=0.989) ‚Üí absurdo , porra que n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.990) ‚Üí absurdo , porra . n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.993) ‚Üí absurdo , porra ? n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.999) ‚Üí absurdo , porra aqui n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.990) ‚Üí absurdo , porra e n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.971) ‚Üí absurdo , porra ela n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.993) ‚Üí absurdo , porra esse n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.992) ‚Üí absurdo , porra , n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.992) ‚Üí absurdo , porra isso n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n‚úÖ Aceito (sim=0.993) ‚Üí absurdo , porra essa n√£o e casa de veraneio . esses parlamentares tem que ser afastados , que palha√ßada\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: vcs precisam fazer um ato em defesa da Amaz√¥nia que continua pegando fogo. Algo precisa ser feito. A situa√ß√£o √© desesperadora!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (10): ['precisam', 'fazer', 'ato', 'defesa', 'Amaz√¥nia', 'continua', 'fogo', 'precisa', 'feito', 'situa√ß√£o']\n Rejeitado (sim=0.641 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da Petrobras que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.679 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da bomba que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.690 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da natureza que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.680 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da cidade que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.604 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da educa√ß√£o que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.762) ‚Üí vcs precisam fazer um ato em defesa da terra que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.605 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da escola que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.659 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da fam√≠lia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n Rejeitado (sim=0.681 < 0.7) ‚Üí vcs precisam fazer um ato em defesa da casa que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.741) ‚Üí vcs precisam fazer um ato em defesa da floresta que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.995) ‚Üí vcs devem fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.994) ‚Üí vcs querem fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.975) ‚Üí vcs podiam fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.993) ‚Üí vcs deveria fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.993) ‚Üí vcs deviam fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.985) ‚Üí vcs podem fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.997) ‚Üí vcs precisam fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n‚úÖ Aceito (sim=0.995) ‚Üí vcs v√£o fazer um ato em defesa da Amaz√¥nia que continua pegando fogo . Algo precisa ser feito . A situa√ß√£o √© desesperadora !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 18 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Muitooo beeem , um juiz forte e seguro, fazendo a justi√ßa valer a pena, parab√©ns.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (6): ['juiz', 'forte', 'seguro', 'fazendo', 'justi√ßa', 'pena']\n‚úÖ Aceito (sim=0.986) ‚Üí Muitooo beeem , um juiz r√°pido e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.974) ‚Üí Muitooo beeem , um juiz experiente e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.982) ‚Üí Muitooo beeem , um juiz inteligente e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.975) ‚Üí Muitooo beeem , um juiz eficiente e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.977) ‚Üí Muitooo beeem , um juiz exemplar e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.987) ‚Üí Muitooo beeem , um juiz s√©rio e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.993) ‚Üí Muitooo beeem , um juiz firme e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.987) ‚Üí Muitooo beeem , um juiz correto e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.971) ‚Üí Muitooo beeem , um juiz respons√°vel e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n‚úÖ Aceito (sim=0.988) ‚Üí Muitooo beeem , um juiz justo e seguro , fazendo a justi√ßa valer a pena , parab√©ns .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Seu √≥dio s√≥ esta fazendo voc√™ fazer besteira\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['√≥dio', 'fazendo', 'fazer']\n‚úÖ Aceito (sim=0.989) ‚Üí Seu √≥dio s√≥ esta por voc√™ fazer besteira\n‚úÖ Aceito (sim=0.987) ‚Üí Seu √≥dio s√≥ esta deixando voc√™ fazer besteira\n‚úÖ Aceito (sim=0.973) ‚Üí Seu √≥dio s√≥ esta se voc√™ fazer besteira\n‚úÖ Aceito (sim=0.944) ‚Üí Seu √≥dio s√≥ esta esperando voc√™ fazer besteira\n Rejeitado: igual ao original ‚Üí Seu √≥dio s√≥ esta fazendo voc√™ fazer besteira\n‚úÖ Aceito (sim=0.983) ‚Üí Seu √≥dio s√≥ esta para voc√™ fazer besteira\n‚úÖ Aceito (sim=0.982) ‚Üí Seu √≥dio s√≥ esta feito voc√™ fazer besteira\n‚úÖ Aceito (sim=0.982) ‚Üí Seu √≥dio s√≥ esta pra voc√™ fazer besteira\n‚úÖ Aceito (sim=0.991) ‚Üí Seu √≥dio s√≥ esta em voc√™ fazer besteira\n‚úÖ Aceito (sim=0.963) ‚Üí Seu √≥dio s√≥ esta vendo voc√™ fazer besteira\n‚úÖ Aceito (sim=0.746) ‚Üí Seu amor s√≥ esta fazendo voc√™ fazer besteira\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Deus √© maior estou com presidente bolsonario\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (3): ['Deus', 'maior', 'presidente']\n‚úÖ Aceito (sim=0.896) ‚Üí Deus √© que estou com presidente bolsonario\n‚úÖ Aceito (sim=0.927) ‚Üí Deus √© pai estou com presidente bolsonario\n‚úÖ Aceito (sim=0.933) ‚Üí Deus √© forte estou com presidente bolsonario\n‚úÖ Aceito (sim=0.916) ‚Üí Deus √© amor estou com presidente bolsonario\n‚úÖ Aceito (sim=0.931) ‚Üí Deus √© fiel estou com presidente bolsonario\n Rejeitado (sim=0.680 < 0.7) ‚Üí Deus √© brasileiro estou com presidente bolsonario\n‚úÖ Aceito (sim=0.911) ‚Üí Deus √© bom estou com presidente bolsonario\n‚úÖ Aceito (sim=0.923) ‚Üí Deus √© nosso estou com presidente bolsonario\n‚úÖ Aceito (sim=0.903) ‚Üí Deus √© vivo estou com presidente bolsonario\n‚úÖ Aceito (sim=0.961) ‚Üí Deus √© grande estou com presidente bolsonario\n‚úÖ Aceito (sim=0.859) ‚Üí Agora √© maior estou com presidente bolsonario\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° acontecendo\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (4): ['qualidade', 'gra√ßas', 'presidente', 'acontecendo']\n Rejeitado: igual ao original ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° acontecendo\n‚úÖ Aceito (sim=0.960) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° funcionando\n‚úÖ Aceito (sim=0.962) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° !\n‚úÖ Aceito (sim=0.927) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° mudando\n‚úÖ Aceito (sim=0.998) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° ocorrendo\n‚úÖ Aceito (sim=0.977) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° feito\n‚úÖ Aceito (sim=0.966) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° .\n‚úÖ Aceito (sim=0.959) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° certo\n‚úÖ Aceito (sim=0.960) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° resolvido\n‚úÖ Aceito (sim=0.983) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz gra√ßas ao nosso presidente isto est√° indo\n‚úÖ Aceito (sim=0.991) ‚Üí Qui lindo estava precisando de uma educa√ßao de qualidade no nosso paiz igual ao nosso presidente isto est√° acontecendo\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Lula vagabundo e bandido !!!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['Lula']\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.556 < 0.7) ‚Üí Sou vagabundo e bandido ! ! !\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado (sim=0.619 < 0.7) ‚Üí Que vagabundo e bandido ! ! !\n Rejeitado (sim=0.592 < 0.7) ‚Üí Tem vagabundo e bandido ! ! !\n Rejeitado (sim=0.622 < 0.7) ‚Üí Povo vagabundo e bandido ! ! !\n Rejeitado (sim=0.598 < 0.7) ‚Üí Tudo vagabundo e bandido ! ! !\n Rejeitado (sim=0.630 < 0.7) ‚Üí Um vagabundo e bandido ! ! !\n Rejeitado (sim=0.619 < 0.7) ‚Üí √â vagabundo e bandido ! ! !\n Rejeitado (sim=0.635 < 0.7) ‚Üí Muito vagabundo e bandido ! ! !\n Rejeitado (sim=0.661 < 0.7) ‚Üí E vagabundo e bandido ! ! !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 0 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Pois ela √© uma sem vergonha\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: Me solidarizo com a senhora ministra, esse ser que escreveu √© completamente desprovido de √©tica, dec√™ncia, indoli, moral, um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (12): ['senhora', 'escreveu', 'completamente', '√©tica', 'moral', 'lixo', 'sociedade', 'traz', 'consigo', 'educa√ß√£o', 'recebeu', 'pr√≥pria']\n‚úÖ Aceito (sim=0.993) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© muito desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.997) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© absolutamente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.994) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© extremamente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.991) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© t√£o desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.986) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© , desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.998) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© totalmente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.990) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© simplesmente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.998) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© completamente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.978) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© um desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n‚úÖ Aceito (sim=0.996) ‚Üí Me solidarizo com a senhora ministra , esse ser que escreveu √© inteiramente desprovido de √©tica , dec√™ncia , indoli , moral , um lixo da sociedade e traz consigo a educa√ß√£o que recebeu da pr√≥pria progenitora .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Eu concordo com essa legenda sim, tb sou contra essa objetiva√ß√£o do corpo feminino, mas temos que aplaudir essa conquista, um evento t√£o onde a branquitude sempre reinou\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (10): ['legenda', 'sim', 'contra', 'corpo', 'feminino', 'conquista', 'evento', 't√£o', 'onde', 'sempre']\n‚úÖ Aceito (sim=0.951) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um pa√≠s t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.930) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um pais t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.976) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um lugar t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.968) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um mundo t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.812) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um Brasil t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.972) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um local t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.968) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um espa√ßo t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.950) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um sonho t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.987) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um momento t√£o onde a branquitude sempre reinou\n‚úÖ Aceito (sim=0.964) ‚Üí Eu concordo com essa legenda sim , tb sou contra essa objetiva√ß√£o do corpo feminino , mas temos que aplaudir essa conquista , um corpo t√£o onde a branquitude sempre reinou\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: G√™nios\n----------------------------------------------------------------------------------------------------\n Frase muito curta (menos de 3 tokens).\n====================================================================================================\n====================================================================================================\nüìù Texto original: Finalmente algu√©m que merece !\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['Finalmente', 'algu√©m']\n‚úÖ Aceito (sim=0.922) ‚Üí Por algu√©m que merece !\n‚úÖ Aceito (sim=0.925) ‚Üí E algu√©m que merece !\n‚úÖ Aceito (sim=0.915) ‚Üí Para algu√©m que merece !\n‚úÖ Aceito (sim=0.821) ‚Üí Era algu√©m que merece !\n‚úÖ Aceito (sim=0.936) ‚Üí H√° algu√©m que merece !\n‚úÖ Aceito (sim=0.914) ‚Üí Tem algu√©m que merece !\n‚úÖ Aceito (sim=0.775) ‚Üí Sou algu√©m que merece !\n‚úÖ Aceito (sim=0.904) ‚Üí Eis algu√©m que merece !\n‚úÖ Aceito (sim=0.920) ‚Üí Mas algu√©m que merece !\n‚úÖ Aceito (sim=0.865) ‚Üí √â algu√©m que merece !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Isso n√£o tem fim\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['fim']\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.555 < 0.7) ‚Üí Isso n√£o tem explica√ß√£o\n Rejeitado (sim=0.579 < 0.7) ‚Üí Isso n√£o tem !\n Rejeitado (sim=0.591 < 0.7) ‚Üí Isso n√£o tem jeito\n Rejeitado (sim=0.563 < 0.7) ‚Üí Isso n√£o tem ?\n Rejeitado (sim=0.454 < 0.7) ‚Üí Isso n√£o tem l√≥gica\n Rejeitado (sim=0.651 < 0.7) ‚Üí Isso n√£o tem problema\n Rejeitado (sim=0.527 < 0.7) ‚Üí Isso n√£o tem pre√ßo\n Rejeitado (sim=0.425 < 0.7) ‚Üí Isso n√£o tem sentido\n Rejeitado (sim=0.631 < 0.7) ‚Üí Isso n√£o tem solu√ß√£o\n Rejeitado (sim=0.551 < 0.7) ‚Üí Isso n√£o tem .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 0 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Deus no comando, dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s!!! somostodasbolsonaro\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (10): ['Deus', 'comando', 'dirigindo', 'm√£os', 'cabe√ßa', 'homens', '√©tica', 'poder', 'agir', 'Pa√≠s']\n‚úÖ Aceito (sim=0.781) ‚Üí Est√£o no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.852) ‚Üí Dilma no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.841) ‚Üí Sempre no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n Rejeitado (sim=0.615 < 0.7) ‚Üí Lula no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.814) ‚Üí T√° no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.829) ‚Üí Esta no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.816) ‚Üí Est√° no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.843) ‚Üí E no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.827) ‚Üí Fica no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.819) ‚Üí Temer no comando , dirigindo as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n‚úÖ Aceito (sim=0.961) ‚Üí Deus no comando , colocando as m√£os e a cabe√ßa dos homens de √©tica e poder para agir em nosso Pa√≠s ! ! ! somostodasbolsonaro\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Ja passou,da hora de sa√≠rem de cena seus comunistas da globo lixo!!!\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (7): ['Ja', 'passou', 'hora', 'cena', 'comunistas', 'globo', 'lixo']\n‚úÖ Aceito (sim=0.958) ‚Üí Ja passou , da fase de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.971) ‚Üí Ja passou , da tempo de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.903) ‚Üí Ja passou , da metade de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.977) ‚Üí Ja passou , da hora de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.974) ‚Üí Ja passou , da altura de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.938) ‚Üí Ja passou , da vontade de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.938) ‚Üí Ja passou , da vez de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.930) ‚Üí Ja passou , da idade de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.953) ‚Üí Ja passou , da era de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n‚úÖ Aceito (sim=0.967) ‚Üí Ja passou , da √©poca de sa√≠rem de cena seus comunistas da globo lixo ! ! !\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Melhor coisa do mundo gente imparcial\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (4): ['Melhor', 'coisa', 'mundo', 'gente']\n‚úÖ Aceito (sim=0.959) ‚Üí Melhor coisa do mundo - imparcial\n‚úÖ Aceito (sim=0.960) ‚Üí Melhor coisa do mundo e imparcial\n‚úÖ Aceito (sim=0.963) ‚Üí Melhor coisa do mundo sendo imparcial\n‚úÖ Aceito (sim=0.929) ‚Üí Melhor coisa do mundo √© imparcial\n‚úÖ Aceito (sim=0.950) ‚Üí Melhor coisa do mundo : imparcial\n Rejeitado (sim=0.546 < 0.7) ‚Üí Melhor coisa do mundo jornalismo imparcial\n‚úÖ Aceito (sim=0.945) ‚Üí Melhor coisa do mundo Ser imparcial\n‚úÖ Aceito (sim=0.957) ‚Üí Melhor coisa do mundo ‚Äì imparcial\n‚úÖ Aceito (sim=0.948) ‚Üí Melhor coisa do mundo , imparcial\n‚úÖ Aceito (sim=0.951) ‚Üí Melhor coisa do mundo ser imparcial\n Rejeitado: token inv√°lido ([UNK])\n‚úÖ Aceito (sim=0.927) ‚Üí Melhor coisa do planeta gente imparcial\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 12 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Ela ganhou e vai continuar objetificada... Pregui√ßa desses discursos\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (5): ['ganhou', 'vai', 'continuar', 'desses', 'discursos']\n Rejeitado: token inv√°lido ([UNK])\n‚úÖ Aceito (sim=0.920) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses !\n‚úÖ Aceito (sim=0.913) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses .\n‚úÖ Aceito (sim=0.891) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses dias\n‚úÖ Aceito (sim=0.872) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses pol√≠ticos\n‚úÖ Aceito (sim=0.869) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses homens\n‚úÖ Aceito (sim=0.945) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses coment√°rios\n‚úÖ Aceito (sim=0.911) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses cara\n‚úÖ Aceito (sim=0.908) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses :\n‚úÖ Aceito (sim=0.911) ‚Üí Ela ganhou e vai continuar objetificada . . . Pregui√ßa desses ?\n‚úÖ Aceito (sim=0.944) ‚Üí Ela ganhou e deveria continuar objetificada . . . Pregui√ßa desses discursos\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Minha ideologia √© o Brasil, deixa o povo ficar em sil√™ncio...A esquerda toma conta e os oportunistas .\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (9): ['ideologia', 'Brasil', 'deixa', 'povo', 'ficar', 'sil√™ncio', 'esquerda', 'toma', 'conta']\n‚úÖ Aceito (sim=0.993) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma parte e os oportunistas .\n‚úÖ Aceito (sim=0.990) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma , e os oportunistas .\n‚úÖ Aceito (sim=0.996) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma conta e os oportunistas .\n‚úÖ Aceito (sim=0.994) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma frente e os oportunistas .\n‚úÖ Aceito (sim=0.991) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma posi√ß√£o e os oportunistas .\n‚úÖ Aceito (sim=0.985) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma poder e os oportunistas .\n‚úÖ Aceito (sim=0.992) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma posse e os oportunistas .\n‚úÖ Aceito (sim=0.983) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma espa√ßo e os oportunistas .\n‚úÖ Aceito (sim=0.979) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma ruas e os oportunistas .\n‚úÖ Aceito (sim=0.992) ‚Üí Minha ideologia √© o Brasil , deixa o povo ficar em sil√™ncio . . . A esquerda toma partido e os oportunistas .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Que fase chegamos ...\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['fase']\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n‚úÖ Aceito (sim=0.724) ‚Üí Que enfim chegamos . . .\n‚úÖ Aceito (sim=0.773) ‚Üí Que j√° chegamos . . .\n‚úÖ Aceito (sim=0.723) ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n‚úÖ Aceito (sim=0.714) ‚Üí Que mal chegamos . . .\n‚úÖ Aceito (sim=0.739) ‚Üí Que aqui chegamos . . .\n‚úÖ Aceito (sim=0.843) ‚Üí Que ponto chegamos . . .\n‚úÖ Aceito (sim=0.771) ‚Üí Que finalmente chegamos . . .\n‚úÖ Aceito (sim=0.751) ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que l√° chegamos . . .\n J√° gerado ‚Üí Que enfim chegamos . . .\n J√° gerado ‚Üí Que ponto chegamos . . .\n J√° gerado ‚Üí Que mal chegamos . . .\n Rejeitado (sim=0.678 < 0.7) ‚Üí Que dia chegamos . . .\n J√° gerado ‚Üí Que n√≥s chegamos . . .\n Rejeitado (sim=0.551 < 0.7) ‚Üí Que nunca chegamos . . .\n J√° gerado ‚Üí Que finalmente chegamos . . .\n J√° gerado ‚Üí Que j√° chegamos . . .\n J√° gerado ‚Üí Que aqui chegamos . . .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 8 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Damaris me representa\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['representa']\n‚úÖ Aceito (sim=0.888) ‚Üí Damaris me :\n‚úÖ Aceito (sim=0.816) ‚Üí Damaris me disse\n‚úÖ Aceito (sim=0.766) ‚Üí Damaris me ajuda\n‚úÖ Aceito (sim=0.750) ‚Üí Damaris me ama\n‚úÖ Aceito (sim=0.843) ‚Üí Damaris me .\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n‚úÖ Aceito (sim=0.834) ‚Üí Damaris me diz\n‚úÖ Aceito (sim=0.783) ‚Üí Damaris me respondeu\n‚úÖ Aceito (sim=0.753) ‚Üí Damaris me ajudou\n‚úÖ Aceito (sim=0.812) ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me diz\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajuda\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ajuda\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ama\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me responde\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me diz\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me respondeu\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me :\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ama\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me .\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ajuda\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me disse\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me responde\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me .\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me diz\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajudou\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me :\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me ama\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me ama\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me :\n J√° gerado ‚Üí Damaris me ama\n Rejeitado (sim=0.689 < 0.7) ‚Üí Damaris me !\n J√° gerado ‚Üí Damaris me ajuda\n J√° gerado ‚Üí Damaris me ajudou\n J√° gerado ‚Üí Damaris me respondeu\n J√° gerado ‚Üí Damaris me .\n J√° gerado ‚Üí Damaris me disse\n J√° gerado ‚Üí Damaris me diz\n J√° gerado ‚Üí Damaris me responde\n J√° gerado ‚Üí Damaris me :\n----------------------------------------------------------------------------------------------------\n Total aceitas: 9 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Que Dupla mais Especial! LulaLivreJ√°\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['Especial']\n‚úÖ Aceito (sim=0.917) ‚Üí Que Dupla mais bonita ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.918) ‚Üí Que Dupla mais forte ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.796) ‚Üí Que Dupla mais Linda ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.952) ‚Üí Que Dupla mais Bela ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.871) ‚Üí Que Dupla mais feliz ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.930) ‚Üí Que Dupla mais perfeita ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.958) ‚Üí Que Dupla mais legal ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.913) ‚Üí Que Dupla mais poderosa ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.870) ‚Üí Que Dupla mais inteligente ! LulaLivreJ√°\n‚úÖ Aceito (sim=0.934) ‚Üí Que Dupla mais bela ! LulaLivreJ√°\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Am√©m que Deus cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (5): ['Deus', 'pra', 'poder', 'lidar', 'todas']\n‚úÖ Aceito (sim=0.840) ‚Üí Am√©m que Jesus cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.831) ‚Üí Am√©m que nos cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.845) ‚Üí Am√©m que sempre cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=1.000) ‚Üí Am√©m que Deus cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.814) ‚Üí Am√©m que te cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.856) ‚Üí Am√©m que deus cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.829) ‚Üí Am√©m que Ele cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.857) ‚Üí Am√©m que se cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.820) ‚Üí Am√©m que ele cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n‚úÖ Aceito (sim=0.861) ‚Üí Am√©m que Senhor cubra de ben√ß√£os vcs e que d√™ dicertimento pra poder lidar com todas essas afronta dos esquerdista .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: avante meu Brasil\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (1): ['Brasil']\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.402 < 0.7) ‚Üí avante meu irm√£o\n Rejeitado (sim=0.395 < 0.7) ‚Üí avante meu cora√ß√£o\n Rejeitado (sim=0.488 < 0.7) ‚Üí avante meu nome\n Rejeitado (sim=0.346 < 0.7) ‚Üí avante meu blog\n Rejeitado (sim=0.501 < 0.7) ‚Üí avante meu povo\n Rejeitado (sim=0.503 < 0.7) ‚Üí avante meu !\n Rejeitado (sim=0.494 < 0.7) ‚Üí avante meu amor\n Rejeitado (sim=0.406 < 0.7) ‚Üí avante meu pai\n Rejeitado (sim=0.377 < 0.7) ‚Üí avante meu filho\n Rejeitado (sim=0.509 < 0.7) ‚Üí avante meu amigo\n----------------------------------------------------------------------------------------------------\n Total aceitas: 0 / 10 (em 200 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Essa passou na fila da beleza v√°rias vezes\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (4): ['passou', 'beleza', 'v√°rias', 'vezes']\n‚úÖ Aceito (sim=0.954) ‚Üí Essa passou na fila da beleza algumas vezes\n‚úÖ Aceito (sim=0.872) ‚Üí Essa passou na fila da beleza tr√™s vezes\n‚úÖ Aceito (sim=0.954) ‚Üí Essa passou na fila da beleza muitas vezes\n Rejeitado: igual ao original ‚Üí Essa passou na fila da beleza v√°rias vezes\n‚úÖ Aceito (sim=0.873) ‚Üí Essa passou na fila da beleza 4 vezes\n‚úÖ Aceito (sim=0.990) ‚Üí Essa passou na fila da beleza in√∫meras vezes\n‚úÖ Aceito (sim=0.891) ‚Üí Essa passou na fila da beleza duas vezes\n‚úÖ Aceito (sim=0.850) ‚Üí Essa passou na fila da beleza 5 vezes\n‚úÖ Aceito (sim=0.889) ‚Üí Essa passou na fila da beleza 2 vezes\n‚úÖ Aceito (sim=0.875) ‚Üí Essa passou na fila da beleza 3 vezes\n‚úÖ Aceito (sim=0.947) ‚Üí Essa passou na fila da beleza v√°rias .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 11 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Bora Brasil...Lula na Cadeia\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['Brasil', 'Lula']\n‚úÖ Aceito (sim=0.790) ‚Üí Bora Lula . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.965) ‚Üí Bora Brasil . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.775) ‚Üí Bora . . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.711) ‚Üí Bora ver . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.791) ‚Üí Bora PT . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.727) ‚Üí Bora entender . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.710) ‚Üí Bora embora . . . Lula na Cadeia\n Rejeitado (sim=0.653 < 0.7) ‚Üí Bora assistir . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.786) ‚Üí Bora l√° . . . Lula na Cadeia\n Rejeitado (sim=0.595 < 0.7) ‚Üí Bora estudar . . . Lula na Cadeia\n J√° gerado ‚Üí Bora entender . . . Lula na Cadeia\n Rejeitado (sim=0.653 < 0.7) ‚Üí Bora assistir . . . Lula na Cadeia\n J√° gerado ‚Üí Bora Brasil . . . Lula na Cadeia\n Rejeitado (sim=0.595 < 0.7) ‚Üí Bora estudar . . . Lula na Cadeia\n J√° gerado ‚Üí Bora . . . . Lula na Cadeia\n J√° gerado ‚Üí Bora Lula . . . Lula na Cadeia\n J√° gerado ‚Üí Bora ver . . . Lula na Cadeia\n J√° gerado ‚Üí Bora l√° . . . Lula na Cadeia\n J√° gerado ‚Üí Bora embora . . . Lula na Cadeia\n J√° gerado ‚Üí Bora PT . . . Lula na Cadeia\n J√° gerado ‚Üí Bora entender . . . Lula na Cadeia\n Rejeitado (sim=0.595 < 0.7) ‚Üí Bora estudar . . . Lula na Cadeia\n J√° gerado ‚Üí Bora Lula . . . Lula na Cadeia\n J√° gerado ‚Üí Bora . . . . Lula na Cadeia\n J√° gerado ‚Üí Bora Brasil . . . Lula na Cadeia\n J√° gerado ‚Üí Bora ver . . . Lula na Cadeia\n J√° gerado ‚Üí Bora PT . . . Lula na Cadeia\n J√° gerado ‚Üí Bora l√° . . . Lula na Cadeia\n Rejeitado (sim=0.653 < 0.7) ‚Üí Bora assistir . . . Lula na Cadeia\n J√° gerado ‚Üí Bora embora . . . Lula na Cadeia\n J√° gerado ‚Üí Bora Brasil . . . Lula na Cadeia\n‚úÖ Aceito (sim=0.904) ‚Üí Bora Brasil . . . . na Cadeia\n‚úÖ Aceito (sim=0.945) ‚Üí Bora Brasil . . . Entre na Cadeia\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 33 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Poica branca nao can√ßa de passar vergonha. Kkkkkk\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['branca', 'passar']\n‚úÖ Aceito (sim=0.775) ‚Üí Poica se nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.741) ‚Üí Poica mas nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.785) ‚Üí Poica , nao can√ßa de passar vergonha . Kkkkkk\n Rejeitado (sim=0.650 < 0.7) ‚Üí Poica ela nao can√ßa de passar vergonha . Kkkkkk\n Rejeitado: token inv√°lido ([UNK])\n‚úÖ Aceito (sim=0.758) ‚Üí Poica e nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.771) ‚Üí Poica . nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.769) ‚Üí Poica : nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.763) ‚Üí Poica que nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.784) ‚Üí Poica ! nao can√ßa de passar vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.976) ‚Üí Poica branca nao can√ßa de ver vergonha . Kkkkkk\n‚úÖ Aceito (sim=0.996) ‚Üí Poica branca nao can√ßa de passar vergonha . Kkkkkk\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 12 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: Desgra√ßa\n----------------------------------------------------------------------------------------------------\n Nenhuma palavra candidata para mascarar.\n====================================================================================================\n====================================================================================================\nüìù Texto original: O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar. Admirarei eternamente seu pai. Apenas para frisar at√© 2 anos atr√°s eu era esquerdista, e eu era totalmente antibolsonaro. Obrigado por abrirem meus olhos a tempo.\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (21): ['familia', 'fizeram', 'hist√≥rico', 'prova', 'viva', 'real', 'determina√ß√£o', 'real', 'for√ßa', 'vontade', 'humano', 'chega', 'aonde', 'chegar', 'pai', 'Apenas', 'anos', 'atr√°s', 'totalmente', 'olhos', 'tempo']\n‚úÖ Aceito (sim=0.997) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . s√≥ para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . Aqui para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . E para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.997) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . so para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . Isso para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . So para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . S√≥ para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.997) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . Mas para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.997) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . Somente para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n‚úÖ Aceito (sim=0.998) ‚Üí O que voc√™s da familia Bolsonaro fizeram foi hist√≥rico ! Voc√™s s√£o a prova viva de que com real determina√ß√£o e real for√ßa de vontade o ser humano chega aonde ele quiser chegar . Admirarei eternamente seu pai . Apenas para frisar at√© 2 anos atr√°s eu era esquerdista , e eu era totalmente antibolsonaro . Obrigado por abrirem meus olhos a tempo .\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 10 tentativas)\n====================================================================================================\n====================================================================================================\nüìù Texto original: escolhida por quem ?? pela a midia esquerdista heheh ai e facil\n----------------------------------------------------------------------------------------------------\n Tokens candidatos (2): ['escolhida', 'facil']\n‚úÖ Aceito (sim=0.875) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e agora\n‚úÖ Aceito (sim=0.895) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e la\n‚úÖ Aceito (sim=0.873) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e mais\n Rejeitado: token inv√°lido ([UNK])\n‚úÖ Aceito (sim=0.892) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e a\n Rejeitado: token inv√°lido (##h)\n‚úÖ Aceito (sim=0.876) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e .\n Rejeitado: token inv√°lido (##i)\n‚úÖ Aceito (sim=0.886) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e tal\n‚úÖ Aceito (sim=0.884) ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e outra\n Rejeitado: token inv√°lido ([UNK])\n Rejeitado: token inv√°lido (##i)\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e outra\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e a\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e agora\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e .\n Rejeitado: token inv√°lido (##h)\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e mais\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e tal\n J√° gerado ‚Üí escolhida por quem ? ? pela a midia esquerdista heheh ai e la\n‚úÖ Aceito (sim=0.846) ‚Üí ? por quem ? ? pela a midia esquerdista heheh ai e facil\n‚úÖ Aceito (sim=0.851) ‚Üí e por quem ? ? pela a midia esquerdista heheh ai e facil\n‚úÖ Aceito (sim=0.846) ‚Üí √â por quem ? ? pela a midia esquerdista heheh ai e facil\n----------------------------------------------------------------------------------------------------\n Total aceitas: 10 / 10 (em 23 tentativas)\n====================================================================================================\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import random\n",
        "import re\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# ============================================================\n",
        "# 1. Prepara√ß√£o\n",
        "# ============================================================\n",
        "nltk.download(\"stopwords\")\n",
        "stopwords_pt = set(stopwords.words(\"portuguese\"))\n",
        "\n",
        "# Carrega modelo SBERT\n",
        "sbert = SentenceTransformer('/kaggle/input/miniml/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "# ============================================================\n",
        "# 2. Fun√ß√£o de data augmentation (sem prints)\n",
        "# ============================================================\n",
        "def mlm_augment_clean(\n",
        "    text,\n",
        "    tokenizer,\n",
        "    model,\n",
        "    device,\n",
        "    n_aug=10,\n",
        "    top_k=10,\n",
        "    max_tries=20,\n",
        "    min_similarity=0.7,\n",
        "    max_similarity=1.0\n",
        "):\n",
        "    stop_words = set(stopwords.words(\"portuguese\"))\n",
        "    augmented_samples = []\n",
        "\n",
        "    text = re.sub(r\"[‚Äò‚Äô]\", \"'\", text)\n",
        "    text = re.sub(r\"[‚Äú‚Äù]\", '\"', text)\n",
        "\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    if len(tokens) < 3:\n",
        "        return []\n",
        "\n",
        "    def is_full_word(tokens, idx):\n",
        "        if tokens[idx].startswith(\"##\"):\n",
        "            return False\n",
        "        if idx + 1 < len(tokens) and tokens[idx + 1].startswith(\"##\"):\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    candidate_indices = [\n",
        "        i for i, t in enumerate(tokens)\n",
        "        if t.isalpha() and is_full_word(tokens, i) and t.lower() not in stop_words\n",
        "    ]\n",
        "    if not candidate_indices:\n",
        "        return []\n",
        "\n",
        "    orig_emb = sbert.encode(text, convert_to_tensor=True, show_progress_bar=False)\n",
        "\n",
        "    tries = 0\n",
        "    while len(augmented_samples) < n_aug and tries < max_tries:\n",
        "        tries += 1\n",
        "        mask_idx = random.choice(candidate_indices)\n",
        "        masked_tokens = tokens.copy()\n",
        "        masked_tokens[mask_idx] = tokenizer.mask_token\n",
        "        masked_text = tokenizer.convert_tokens_to_string(masked_tokens)\n",
        "\n",
        "        inputs = tokenizer(masked_text, return_tensors=\"pt\").to(device)\n",
        "        mask_positions = (inputs[\"input_ids\"] == tokenizer.mask_token_id).nonzero(as_tuple=False)\n",
        "        if mask_positions.size(0) == 0:\n",
        "            continue\n",
        "        mask_pos = mask_positions[0, 1].item()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        logits = outputs.logits[0, mask_pos]\n",
        "        top_k_ids = torch.topk(logits, k=min(top_k, logits.size(0))).indices.tolist()\n",
        "        random.shuffle(top_k_ids)\n",
        "\n",
        "        for chosen_id in top_k_ids:\n",
        "            new_token = tokenizer.convert_ids_to_tokens([chosen_id])[0]\n",
        "            if new_token == \"[UNK]\" or new_token.startswith(\"##\"):\n",
        "                continue\n",
        "\n",
        "            new_tokens = tokens.copy()\n",
        "            new_tokens[mask_idx] = new_token\n",
        "            new_text = tokenizer.convert_tokens_to_string(new_tokens).strip()\n",
        "\n",
        "            if \"[UNK]\" in new_text or new_text.lower() == text.lower():\n",
        "                continue\n",
        "\n",
        "            new_emb = sbert.encode(new_text, convert_to_tensor=True, show_progress_bar=False)\n",
        "            sim = util.cos_sim(orig_emb, new_emb).item()\n",
        "\n",
        "            if not (min_similarity <= sim <= max_similarity):\n",
        "                continue\n",
        "\n",
        "            if new_text in augmented_samples:\n",
        "                continue\n",
        "\n",
        "            augmented_samples.append(new_text)\n",
        "\n",
        "            if len(augmented_samples) >= n_aug:\n",
        "                break\n",
        "\n",
        "    return augmented_samples\n",
        "\n",
        "# ============================================================\n",
        "# 3. Gera√ß√£o dos 5 datasets\n",
        "# ============================================================\n",
        "intervalos = {\n",
        "    \"sim_0.65_1.00\": (0.65, 1.00),\n",
        "    \"sim_0.70_1.00\": (0.70, 1.00),\n",
        "    \"sim_0.65_0.90\": (0.65, 0.90),\n",
        "    \"sim_0.70_0.90\": (0.70, 0.90),\n",
        "    \"sim_0.70_0.85\": (0.70, 0.85),\n",
        "}\n",
        "\n",
        "train_path = \"/kaggle/input/treinamento-e-teste/train_df.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "\n",
        "# Gera datasets\n",
        "for nome, (min_sim, max_sim) in intervalos.items():\n",
        "    print(f\" Gerando dataset {nome} (intervalo {min_sim}-{max_sim})\")\n",
        "\n",
        "    aug_texts, aug_labels = [], []\n",
        "    for i, row in train_df.iterrows():\n",
        "        novas = mlm_augment_clean(\n",
        "            text=row[\"text\"],\n",
        "            tokenizer=tokenizer,\n",
        "            model=model,\n",
        "            device=device,\n",
        "            n_aug=10,\n",
        "            top_k=10,\n",
        "            max_tries=20,\n",
        "            min_similarity=min_sim,\n",
        "            max_similarity=max_sim,\n",
        "        )\n",
        "        for n in novas:\n",
        "            aug_texts.append(n)\n",
        "            aug_labels.append(row[\"class\"])\n",
        "\n",
        "    df_aug = pd.DataFrame({\"text\": aug_texts, \"class\": aug_labels})\n",
        "    df_final = pd.concat([train_df, df_aug], ignore_index=True)\n",
        "    df_final.to_csv(f\"/kaggle/working/train_aug_{nome}.csv\", index=False)\n",
        "\n",
        "    print(f\" Salvo: /kaggle/working/train_aug_{nome}.csv ‚Äî {len(df_final)} linhas totais\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-01T20:01:04.542248Z",
          "iopub.execute_input": "2025-11-01T20:01:04.542536Z",
          "iopub.status.idle": "2025-11-02T02:43:46.336617Z",
          "shell.execute_reply.started": "2025-11-01T20:01:04.542515Z",
          "shell.execute_reply": "2025-11-02T02:43:46.335782Z"
        },
        "id": "qaNlARYr21tU",
        "outputId": "d19cf068-32ee-484d-868a-f3cc2e3f68e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": " Gerando dataset sim_0.65_1.00 (intervalo 0.65-1.0)\n Salvo: /kaggle/working/train_aug_sim_0.65_1.00.csv ‚Äî 43250 linhas totais\n\n Gerando dataset sim_0.70_1.00 (intervalo 0.7-1.0)\n Salvo: /kaggle/working/train_aug_sim_0.70_1.00.csv ‚Äî 42459 linhas totais\n\n Gerando dataset sim_0.65_0.90 (intervalo 0.65-0.9)\n Salvo: /kaggle/working/train_aug_sim_0.65_0.90.csv ‚Äî 32193 linhas totais\n\n Gerando dataset sim_0.70_0.90 (intervalo 0.7-0.9)\n Salvo: /kaggle/working/train_aug_sim_0.70_0.90.csv ‚Äî 30551 linhas totais\n\n Gerando dataset sim_0.70_0.85 (intervalo 0.7-0.85)\n Salvo: /kaggle/working/train_aug_sim_0.70_0.85.csv ‚Äî 22515 linhas totais\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# ============================================================\n",
        "# 1) Configura√ß√µes\n",
        "# ============================================================\n",
        "model_name = \"/kaggle/input/bertimbau-tcc-model/bert-base-portuguese-cased\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "base_input = \"/kaggle/input/treinamentoad\"\n",
        "datasets_paths = {\n",
        "    \"sim_0.65_1.00\": \"/kaggle/working/train_aug_sim_0.65_1.00.csv\",\n",
        "    \"sim_0.70_1.00\": \"/kaggle/working/train_aug_sim_0.70_1.00.csv\",\n",
        "    \"sim_0.65_0.90\": \"/kaggle/working/train_aug_sim_0.65_0.90.csv\",\n",
        "    \"sim_0.70_0.90\": \"/kaggle/working/train_aug_sim_0.70_0.90.csv\",\n",
        "    \"sim_0.70_0.85\": \"/kaggle/working/train_aug_sim_0.70_0.85.csv\",\n",
        "}\n",
        "\n",
        "test_path = \"/kaggle/input/treinamento-e-teste/test_df.csv\"\n",
        "test_df = pd.read_csv(test_path)\n",
        "test_df = test_df.rename(columns={\"class\": \"labels\"})\n",
        "\n",
        "# ============================================================\n",
        "# 2) Fun√ß√µes utilit√°rias\n",
        "# ============================================================\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "\n",
        "def compute_metrics(p):\n",
        "    preds = np.argmax(p.predictions, axis=1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average=\"binary\")\n",
        "    acc = accuracy_score(p.label_ids, preds)\n",
        "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
        "\n",
        "# ============================================================\n",
        "# 3) Avaliar cada dataset\n",
        "# ============================================================\n",
        "results = []\n",
        "\n",
        "for name, path in datasets_paths.items():\n",
        "    print(f\"\\n Treinando modelo para dataset: {name}\")\n",
        "\n",
        "    # Carregar dataset\n",
        "    train_df = pd.read_csv(path)\n",
        "    if \"class\" in train_df.columns:\n",
        "        train_df = train_df.rename(columns={\"class\": \"labels\"})\n",
        "\n",
        "    # Limpeza\n",
        "    train_df = train_df.drop_duplicates(subset=[\"text\"], keep=\"first\").dropna(subset=[\"text\", \"labels\"]).reset_index(drop=True)\n",
        "    train_df[\"text\"] = train_df[\"text\"].astype(str)\n",
        "\n",
        "    # Tokeniza√ß√£o\n",
        "    train_dataset = Dataset.from_pandas(train_df)\n",
        "    test_dataset = Dataset.from_pandas(test_df)\n",
        "    train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
        "    test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
        "    train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "    test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "    # Modelo e treino\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"./results_{name}\",\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"no\",\n",
        "        learning_rate=2e-5,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        num_train_epochs=1,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f\"./logs_{name}\",\n",
        "        logging_steps=100,\n",
        "        report_to=\"none\"  # evita logs no WandB\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=test_dataset,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "    metrics = trainer.evaluate()\n",
        "\n",
        "    results.append({\n",
        "        \"dataset\": name,\n",
        "        \"accuracy\": metrics[\"eval_accuracy\"],\n",
        "        \"precision\": metrics[\"eval_precision\"],\n",
        "        \"recall\": metrics[\"eval_recall\"],\n",
        "        \"f1\": metrics[\"eval_f1\"]\n",
        "    })\n",
        "\n",
        "# ============================================================\n",
        "# 4) Resumo comparativo\n",
        "# ============================================================\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values(by=\"f1\", ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\n RESULTADOS FINAIS\")\n",
        "print(results_df)\n",
        "\n",
        "# Salvar resultados\n",
        "results_df.to_csv(\"/kaggle/working/bert_results_comparativo.csv\", index=False)\n",
        "print(\"\\n Resultados salvos em /kaggle/working/bert_results_comparativo.csv\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-02T03:27:52.263788Z",
          "iopub.execute_input": "2025-11-02T03:27:52.264281Z",
          "iopub.status.idle": "2025-11-02T04:21:53.898103Z",
          "shell.execute_reply.started": "2025-11-02T03:27:52.264248Z",
          "shell.execute_reply": "2025-11-02T04:21:53.897337Z"
        },
        "colab": {
          "referenced_widgets": [
            "62c65c4a093a41d69fee98d739c34568",
            "b5120d9be1d444259737ce7ffd51f133",
            "a68c4619794c4846a04279c0097f69fd",
            "d5cac0ed1f7f4661a4c83af6ddb14f07",
            "29f7fd4cc6c04b1eb52765e080c43494",
            "f61da9cfc911479cb411cc67be099dbf",
            "aa4f34feece84a19b171ab336dd88ebe",
            "5d3dfd432ac34a0d883d77555fa12186",
            "e09442b044484107a6b5c7ead3baca00",
            "09cf8dc056e24896aab4e365da473144"
          ]
        },
        "id": "iKsn0tt821tV",
        "outputId": "bbd7c155-a66e-4ec8-c744-8d9f4eb59dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\n Treinando modelo para dataset: sim_0.65_1.00\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/43042 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "62c65c4a093a41d69fee98d739c34568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b5120d9be1d444259737ce7ffd51f133"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/856745935.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.4966, 'grad_norm': 9.776448249816895, 'learning_rate': 1.9264214046822744e-05, 'epoch': 0.03716090672612412}\n{'loss': 0.2716, 'grad_norm': 9.232985496520996, 'learning_rate': 1.8520995912300262e-05, 'epoch': 0.07432181345224824}\n{'loss': 0.2242, 'grad_norm': 14.672833442687988, 'learning_rate': 1.7777777777777777e-05, 'epoch': 0.11148272017837235}\n{'loss': 0.2181, 'grad_norm': 9.53431224822998, 'learning_rate': 1.7034559643255298e-05, 'epoch': 0.14864362690449648}\n{'loss': 0.2009, 'grad_norm': 11.961630821228027, 'learning_rate': 1.6291341508732813e-05, 'epoch': 0.18580453363062058}\n{'loss': 0.1617, 'grad_norm': 1.8552415370941162, 'learning_rate': 1.554812337421033e-05, 'epoch': 0.2229654403567447}\n{'loss': 0.1348, 'grad_norm': 7.390620231628418, 'learning_rate': 1.480490523968785e-05, 'epoch': 0.2601263470828688}\n{'loss': 0.1331, 'grad_norm': 0.32121601700782776, 'learning_rate': 1.4061687105165367e-05, 'epoch': 0.29728725380899296}\n{'loss': 0.1296, 'grad_norm': 19.923917770385742, 'learning_rate': 1.3318468970642883e-05, 'epoch': 0.33444816053511706}\n{'loss': 0.1019, 'grad_norm': 3.3491640090942383, 'learning_rate': 1.2575250836120403e-05, 'epoch': 0.37160906726124115}\n{'loss': 0.1001, 'grad_norm': 5.965787410736084, 'learning_rate': 1.183203270159792e-05, 'epoch': 0.4087699739873653}\n{'loss': 0.0947, 'grad_norm': 0.12049790471792221, 'learning_rate': 1.1088814567075437e-05, 'epoch': 0.4459308807134894}\n{'loss': 0.0697, 'grad_norm': 19.423259735107422, 'learning_rate': 1.0345596432552955e-05, 'epoch': 0.4830917874396135}\n{'loss': 0.0616, 'grad_norm': 1.275712490081787, 'learning_rate': 9.602378298030473e-06, 'epoch': 0.5202526941657376}\n{'loss': 0.0641, 'grad_norm': 52.496883392333984, 'learning_rate': 8.85916016350799e-06, 'epoch': 0.5574136008918618}\n{'loss': 0.0637, 'grad_norm': 31.439712524414062, 'learning_rate': 8.115942028985508e-06, 'epoch': 0.5945745076179859}\n{'loss': 0.082, 'grad_norm': 0.04283472150564194, 'learning_rate': 7.372723894463026e-06, 'epoch': 0.63173541434411}\n{'loss': 0.0464, 'grad_norm': 39.134246826171875, 'learning_rate': 6.629505759940543e-06, 'epoch': 0.6688963210702341}\n{'loss': 0.0402, 'grad_norm': 23.077251434326172, 'learning_rate': 5.886287625418061e-06, 'epoch': 0.7060572277963583}\n{'loss': 0.0363, 'grad_norm': 0.023564498871564865, 'learning_rate': 5.143069490895578e-06, 'epoch': 0.7432181345224823}\n{'loss': 0.0341, 'grad_norm': 125.05956268310547, 'learning_rate': 4.399851356373096e-06, 'epoch': 0.7803790412486065}\n{'loss': 0.0485, 'grad_norm': 0.02533542551100254, 'learning_rate': 3.6566332218506133e-06, 'epoch': 0.8175399479747306}\n{'loss': 0.0493, 'grad_norm': 2.8617639541625977, 'learning_rate': 2.913415087328131e-06, 'epoch': 0.8547008547008547}\n{'loss': 0.0332, 'grad_norm': 0.03815872222185135, 'learning_rate': 2.1701969528056486e-06, 'epoch': 0.8918617614269788}\n{'loss': 0.0335, 'grad_norm': 0.020233625546097755, 'learning_rate': 1.4269788182831662e-06, 'epoch': 0.929022668153103}\n{'loss': 0.0235, 'grad_norm': 0.02519232966005802, 'learning_rate': 6.837606837606839e-07, 'epoch': 0.966183574879227}\n{'eval_loss': 0.47083353996276855, 'eval_accuracy': 0.9098422238918107, 'eval_precision': 0.8998548621190131, 'eval_recall': 0.9239940387481371, 'eval_f1': 0.911764705882353, 'eval_runtime': 7.9444, 'eval_samples_per_second': 167.54, 'eval_steps_per_second': 10.574, 'epoch': 1.0}\n{'train_runtime': 797.7713, 'train_samples_per_second': 53.953, 'train_steps_per_second': 3.373, 'train_loss': 0.1108710030471025, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.47083353996276855, 'eval_accuracy': 0.9098422238918107, 'eval_precision': 0.8998548621190131, 'eval_recall': 0.9239940387481371, 'eval_f1': 0.911764705882353, 'eval_runtime': 7.4974, 'eval_samples_per_second': 177.529, 'eval_steps_per_second': 11.204, 'epoch': 1.0}\n\n Treinando modelo para dataset: sim_0.70_1.00\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/42297 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a68c4619794c4846a04279c0097f69fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5cac0ed1f7f4661a4c83af6ddb14f07"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/856745935.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.4894, 'grad_norm': 11.112591743469238, 'learning_rate': 1.9251134644478065e-05, 'epoch': 0.037821482602118005}\n{'loss': 0.279, 'grad_norm': 12.085649490356445, 'learning_rate': 1.8494704992435706e-05, 'epoch': 0.07564296520423601}\n{'loss': 0.2349, 'grad_norm': 3.029345750808716, 'learning_rate': 1.7738275340393343e-05, 'epoch': 0.11346444780635401}\n{'loss': 0.2203, 'grad_norm': 22.723520278930664, 'learning_rate': 1.6981845688350985e-05, 'epoch': 0.15128593040847202}\n{'loss': 0.1687, 'grad_norm': 7.264078140258789, 'learning_rate': 1.6225416036308626e-05, 'epoch': 0.18910741301059}\n{'loss': 0.1779, 'grad_norm': 5.5061564445495605, 'learning_rate': 1.5468986384266263e-05, 'epoch': 0.22692889561270801}\n{'loss': 0.1414, 'grad_norm': 21.42954444885254, 'learning_rate': 1.4712556732223904e-05, 'epoch': 0.264750378214826}\n{'loss': 0.1227, 'grad_norm': 3.3844833374023438, 'learning_rate': 1.3956127080181545e-05, 'epoch': 0.30257186081694404}\n{'loss': 0.1291, 'grad_norm': 11.468528747558594, 'learning_rate': 1.3199697428139185e-05, 'epoch': 0.340393343419062}\n{'loss': 0.0892, 'grad_norm': 0.0712568461894989, 'learning_rate': 1.2443267776096824e-05, 'epoch': 0.37821482602118}\n{'loss': 0.0841, 'grad_norm': 3.1449575424194336, 'learning_rate': 1.1686838124054465e-05, 'epoch': 0.41603630862329805}\n{'loss': 0.0898, 'grad_norm': 0.07091207057237625, 'learning_rate': 1.0930408472012105e-05, 'epoch': 0.45385779122541603}\n{'loss': 0.0574, 'grad_norm': 0.034518711268901825, 'learning_rate': 1.0173978819969742e-05, 'epoch': 0.491679273827534}\n{'loss': 0.0782, 'grad_norm': 0.03257644176483154, 'learning_rate': 9.417549167927384e-06, 'epoch': 0.529500756429652}\n{'loss': 0.0575, 'grad_norm': 0.03225119039416313, 'learning_rate': 8.661119515885023e-06, 'epoch': 0.56732223903177}\n{'loss': 0.046, 'grad_norm': 94.07250213623047, 'learning_rate': 7.904689863842662e-06, 'epoch': 0.6051437216338881}\n{'loss': 0.0723, 'grad_norm': 30.760318756103516, 'learning_rate': 7.148260211800303e-06, 'epoch': 0.642965204236006}\n{'loss': 0.0456, 'grad_norm': 45.52056121826172, 'learning_rate': 6.391830559757944e-06, 'epoch': 0.680786686838124}\n{'loss': 0.0304, 'grad_norm': 89.83997344970703, 'learning_rate': 5.635400907715582e-06, 'epoch': 0.7186081694402421}\n{'loss': 0.0388, 'grad_norm': 0.015745701268315315, 'learning_rate': 4.8789712556732224e-06, 'epoch': 0.75642965204236}\n{'loss': 0.0449, 'grad_norm': 1.9139037132263184, 'learning_rate': 4.122541603630863e-06, 'epoch': 0.794251134644478}\n{'loss': 0.0387, 'grad_norm': 0.04091695323586464, 'learning_rate': 3.3661119515885025e-06, 'epoch': 0.8320726172465961}\n{'loss': 0.0343, 'grad_norm': 0.01167156919836998, 'learning_rate': 2.6096822995461423e-06, 'epoch': 0.869894099848714}\n{'loss': 0.0264, 'grad_norm': 0.02040814980864525, 'learning_rate': 1.8532526475037823e-06, 'epoch': 0.9077155824508321}\n{'loss': 0.0298, 'grad_norm': 0.05268596112728119, 'learning_rate': 1.0968229954614222e-06, 'epoch': 0.9455370650529501}\n{'loss': 0.0368, 'grad_norm': 0.3811482787132263, 'learning_rate': 3.4039334341906203e-07, 'epoch': 0.983358547655068}\n{'eval_loss': 0.5128214359283447, 'eval_accuracy': 0.9098422238918107, 'eval_precision': 0.9021897810218978, 'eval_recall': 0.9210134128166915, 'eval_f1': 0.911504424778761, 'eval_runtime': 7.5054, 'eval_samples_per_second': 177.338, 'eval_steps_per_second': 11.192, 'epoch': 1.0}\n{'train_runtime': 789.7553, 'train_samples_per_second': 53.557, 'train_steps_per_second': 3.348, 'train_loss': 0.10900265312050547, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.5128214359283447, 'eval_accuracy': 0.9098422238918107, 'eval_precision': 0.9021897810218978, 'eval_recall': 0.9210134128166915, 'eval_f1': 0.911504424778761, 'eval_runtime': 7.9681, 'eval_samples_per_second': 167.04, 'eval_steps_per_second': 10.542, 'epoch': 1.0}\n\n Treinando modelo para dataset: sim_0.65_0.90\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/32022 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29f7fd4cc6c04b1eb52765e080c43494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f61da9cfc911479cb411cc67be099dbf"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/856745935.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.4423, 'grad_norm': 6.67209529876709, 'learning_rate': 1.901098901098901e-05, 'epoch': 0.04995004995004995}\n{'loss': 0.2673, 'grad_norm': 9.299182891845703, 'learning_rate': 1.8011988011988013e-05, 'epoch': 0.0999000999000999}\n{'loss': 0.2117, 'grad_norm': 28.370769500732422, 'learning_rate': 1.7012987012987013e-05, 'epoch': 0.14985014985014986}\n{'loss': 0.2007, 'grad_norm': 18.101728439331055, 'learning_rate': 1.6013986013986016e-05, 'epoch': 0.1998001998001998}\n{'loss': 0.2008, 'grad_norm': 0.616071343421936, 'learning_rate': 1.5014985014985016e-05, 'epoch': 0.24975024975024976}\n{'loss': 0.1685, 'grad_norm': 0.3248981237411499, 'learning_rate': 1.4015984015984017e-05, 'epoch': 0.2997002997002997}\n{'loss': 0.1692, 'grad_norm': 0.8367102146148682, 'learning_rate': 1.3016983016983018e-05, 'epoch': 0.34965034965034963}\n{'loss': 0.1542, 'grad_norm': 20.012964248657227, 'learning_rate': 1.201798201798202e-05, 'epoch': 0.3996003996003996}\n{'loss': 0.1501, 'grad_norm': 11.327555656433105, 'learning_rate': 1.1018981018981021e-05, 'epoch': 0.44955044955044954}\n{'loss': 0.1127, 'grad_norm': 0.726497232913971, 'learning_rate': 1.001998001998002e-05, 'epoch': 0.4995004995004995}\n{'loss': 0.1003, 'grad_norm': 16.1820068359375, 'learning_rate': 9.020979020979022e-06, 'epoch': 0.5494505494505495}\n{'loss': 0.0909, 'grad_norm': 13.229201316833496, 'learning_rate': 8.021978021978023e-06, 'epoch': 0.5994005994005994}\n{'loss': 0.092, 'grad_norm': 3.5692853927612305, 'learning_rate': 7.022977022977023e-06, 'epoch': 0.6493506493506493}\n{'loss': 0.079, 'grad_norm': 4.3935089111328125, 'learning_rate': 6.023976023976024e-06, 'epoch': 0.6993006993006993}\n{'loss': 0.1072, 'grad_norm': 2.773955821990967, 'learning_rate': 5.024975024975025e-06, 'epoch': 0.7492507492507493}\n{'loss': 0.0718, 'grad_norm': 4.410767078399658, 'learning_rate': 4.025974025974026e-06, 'epoch': 0.7992007992007992}\n{'loss': 0.0784, 'grad_norm': 0.12047725170850754, 'learning_rate': 3.0269730269730276e-06, 'epoch': 0.8491508491508492}\n{'loss': 0.1072, 'grad_norm': 0.8560519218444824, 'learning_rate': 2.027972027972028e-06, 'epoch': 0.8991008991008991}\n{'loss': 0.0804, 'grad_norm': 37.83041000366211, 'learning_rate': 1.028971028971029e-06, 'epoch': 0.949050949050949}\n{'loss': 0.0581, 'grad_norm': 10.597241401672363, 'learning_rate': 2.9970029970029975e-08, 'epoch': 0.999000999000999}\n{'eval_loss': 0.40883952379226685, 'eval_accuracy': 0.9135987978963186, 'eval_precision': 0.9161676646706587, 'eval_recall': 0.9120715350223547, 'eval_f1': 0.9141150112023899, 'eval_runtime': 7.5441, 'eval_samples_per_second': 176.429, 'eval_steps_per_second': 11.134, 'epoch': 1.0}\n{'train_runtime': 598.1528, 'train_samples_per_second': 53.535, 'train_steps_per_second': 3.347, 'train_loss': 0.1469860846668921, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.40883952379226685, 'eval_accuracy': 0.9135987978963186, 'eval_precision': 0.9161676646706587, 'eval_recall': 0.9120715350223547, 'eval_f1': 0.9141150112023899, 'eval_runtime': 7.5127, 'eval_samples_per_second': 177.167, 'eval_steps_per_second': 11.181, 'epoch': 1.0}\n\n Treinando modelo para dataset: sim_0.70_0.90\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/30425 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa4f34feece84a19b171ab336dd88ebe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d3dfd432ac34a0d883d77555fa12186"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/856745935.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.4668, 'grad_norm': 6.30980110168457, 'learning_rate': 1.8958990536277605e-05, 'epoch': 0.052576235541535225}\n{'loss': 0.2816, 'grad_norm': 12.72677993774414, 'learning_rate': 1.79074658254469e-05, 'epoch': 0.10515247108307045}\n{'loss': 0.2451, 'grad_norm': 26.101152420043945, 'learning_rate': 1.6855941114616193e-05, 'epoch': 0.15772870662460567}\n{'loss': 0.2084, 'grad_norm': 5.195542335510254, 'learning_rate': 1.580441640378549e-05, 'epoch': 0.2103049421661409}\n{'loss': 0.1751, 'grad_norm': 7.388441562652588, 'learning_rate': 1.4752891692954785e-05, 'epoch': 0.2628811777076761}\n{'loss': 0.1635, 'grad_norm': 12.211200714111328, 'learning_rate': 1.370136698212408e-05, 'epoch': 0.31545741324921134}\n{'loss': 0.1539, 'grad_norm': 2.483710527420044, 'learning_rate': 1.2649842271293376e-05, 'epoch': 0.36803364879074657}\n{'loss': 0.1283, 'grad_norm': 0.6179376244544983, 'learning_rate': 1.159831756046267e-05, 'epoch': 0.4206098843322818}\n{'loss': 0.1296, 'grad_norm': 2.904188394546509, 'learning_rate': 1.0546792849631968e-05, 'epoch': 0.47318611987381703}\n{'loss': 0.1141, 'grad_norm': 5.186558723449707, 'learning_rate': 9.495268138801262e-06, 'epoch': 0.5257623554153522}\n{'loss': 0.11, 'grad_norm': 5.446219444274902, 'learning_rate': 8.443743427970557e-06, 'epoch': 0.5783385909568874}\n{'loss': 0.0955, 'grad_norm': 0.5324026942253113, 'learning_rate': 7.392218717139853e-06, 'epoch': 0.6309148264984227}\n{'loss': 0.0847, 'grad_norm': 0.28184831142425537, 'learning_rate': 6.340694006309149e-06, 'epoch': 0.6834910620399579}\n{'loss': 0.1159, 'grad_norm': 15.368865966796875, 'learning_rate': 5.289169295478444e-06, 'epoch': 0.7360672975814931}\n{'loss': 0.0682, 'grad_norm': 0.06054043397307396, 'learning_rate': 4.2376445846477395e-06, 'epoch': 0.7886435331230284}\n{'loss': 0.0778, 'grad_norm': 0.1836797297000885, 'learning_rate': 3.186119873817035e-06, 'epoch': 0.8412197686645636}\n{'loss': 0.0726, 'grad_norm': 0.19299344718456268, 'learning_rate': 2.1345951629863304e-06, 'epoch': 0.8937960042060988}\n{'loss': 0.0657, 'grad_norm': 0.03403288498520851, 'learning_rate': 1.0830704521556258e-06, 'epoch': 0.9463722397476341}\n{'loss': 0.0486, 'grad_norm': 5.001607894897461, 'learning_rate': 3.1545741324921134e-08, 'epoch': 0.9989484752891693}\n{'eval_loss': 0.43323007225990295, 'eval_accuracy': 0.9075882794891059, 'eval_precision': 0.9041297935103245, 'eval_recall': 0.9135618479880775, 'eval_f1': 0.9088213491475168, 'eval_runtime': 7.5512, 'eval_samples_per_second': 176.263, 'eval_steps_per_second': 11.124, 'epoch': 1.0}\n{'train_runtime': 569.6678, 'train_samples_per_second': 53.408, 'train_steps_per_second': 3.339, 'train_loss': 0.1477366320467647, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.43323007225990295, 'eval_accuracy': 0.9075882794891059, 'eval_precision': 0.9041297935103245, 'eval_recall': 0.9135618479880775, 'eval_f1': 0.9088213491475168, 'eval_runtime': 7.507, 'eval_samples_per_second': 177.3, 'eval_steps_per_second': 11.19, 'epoch': 1.0}\n\n Treinando modelo para dataset: sim_0.70_0.85\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/22416 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e09442b044484107a6b5c7ead3baca00"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Map:   0%|          | 0/1331 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09cf8dc056e24896aab4e365da473144"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_37/856745935.py:84: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'loss': 0.4582, 'grad_norm': 8.00192642211914, 'learning_rate': 1.858672376873662e-05, 'epoch': 0.07137758743754462}\n{'loss': 0.2877, 'grad_norm': 5.8521952629089355, 'learning_rate': 1.7159172019985725e-05, 'epoch': 0.14275517487508924}\n{'loss': 0.2215, 'grad_norm': 0.45973750948905945, 'learning_rate': 1.5731620271234832e-05, 'epoch': 0.21413276231263384}\n{'loss': 0.2057, 'grad_norm': 11.597918510437012, 'learning_rate': 1.430406852248394e-05, 'epoch': 0.28551034975017847}\n{'loss': 0.1933, 'grad_norm': 6.175741195678711, 'learning_rate': 1.287651677373305e-05, 'epoch': 0.35688793718772305}\n{'loss': 0.1831, 'grad_norm': 13.074370384216309, 'learning_rate': 1.1448965024982157e-05, 'epoch': 0.4282655246252677}\n{'loss': 0.1498, 'grad_norm': 16.43013572692871, 'learning_rate': 1.0021413276231265e-05, 'epoch': 0.49964311206281226}\n{'loss': 0.1335, 'grad_norm': 0.10346709191799164, 'learning_rate': 8.593861527480372e-06, 'epoch': 0.5710206995003569}\n{'loss': 0.0973, 'grad_norm': 0.074566550552845, 'learning_rate': 7.16630977872948e-06, 'epoch': 0.6423982869379015}\n{'loss': 0.149, 'grad_norm': 2.1300570964813232, 'learning_rate': 5.7387580299785874e-06, 'epoch': 0.7137758743754461}\n{'loss': 0.1259, 'grad_norm': 12.67069149017334, 'learning_rate': 4.311206281227695e-06, 'epoch': 0.7851534618129907}\n{'loss': 0.1018, 'grad_norm': 11.330887794494629, 'learning_rate': 2.8836545324768023e-06, 'epoch': 0.8565310492505354}\n{'loss': 0.1245, 'grad_norm': 0.06937878578901291, 'learning_rate': 1.4561027837259102e-06, 'epoch': 0.92790863668808}\n{'loss': 0.0953, 'grad_norm': 0.3132041096687317, 'learning_rate': 2.855103497501785e-08, 'epoch': 0.9992862241256245}\n{'eval_loss': 0.39392223954200745, 'eval_accuracy': 0.9075882794891059, 'eval_precision': 0.9053254437869822, 'eval_recall': 0.9120715350223547, 'eval_f1': 0.9086859688195991, 'eval_runtime': 7.5267, 'eval_samples_per_second': 176.837, 'eval_steps_per_second': 11.16, 'epoch': 1.0}\n{'train_runtime': 421.5463, 'train_samples_per_second': 53.176, 'train_steps_per_second': 3.323, 'train_loss': 0.18056624130127177, 'epoch': 1.0}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "{'eval_loss': 0.39392223954200745, 'eval_accuracy': 0.9075882794891059, 'eval_precision': 0.9053254437869822, 'eval_recall': 0.9120715350223547, 'eval_f1': 0.9086859688195991, 'eval_runtime': 7.5033, 'eval_samples_per_second': 177.39, 'eval_steps_per_second': 11.195, 'epoch': 1.0}\n\n RESULTADOS FINAIS\n         dataset  accuracy  precision    recall        f1\n0  sim_0.65_0.90  0.913599   0.916168  0.912072  0.914115\n1  sim_0.65_1.00  0.909842   0.899855  0.923994  0.911765\n2  sim_0.70_1.00  0.909842   0.902190  0.921013  0.911504\n3  sim_0.70_0.90  0.907588   0.904130  0.913562  0.908821\n4  sim_0.70_0.85  0.907588   0.905325  0.912072  0.908686\n\n Resultados salvos em /kaggle/working/bert_results_comparativo.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}